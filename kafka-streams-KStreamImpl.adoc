== [[KStreamImpl]] KStreamImpl

`KStreamImpl` is a concrete link:kafka-streams-KStream.adoc[KStream] (and the one and only in Kafka Streams).

`KStreamImpl` is <<creating-instance, created>> every time a transformation is executed and when...FIXME

[[internal-registries]]
.KStreamImpl's Internal Properties (e.g. Registries, Counters and Flags)
[cols="1,2",options="header",width="100%"]
|===
| Name
| Description

| [[defaultKeyValueMapper]] `defaultKeyValueMapper`
| link:kafka-streams-KeyValueMapper.adoc[KeyValueMapper]
|===

=== [[doStreamTableJoin]] `doStreamTableJoin` Internal Method

[source, java]
----
<V1, R> KStream<K, R> doStreamTableJoin(
  final KTable<K, V1> other,
  final ValueJoiner<? super V, ? super V1, ? extends R> joiner,
  final boolean leftJoin)
----

`doStreamTableJoin`...FIXME

NOTE: `doStreamTableJoin` is used when...FIXME

=== [[doJoin]] `doJoin` Internal Method

[source, java]
----
<V1, R> KStream<K, R> doJoin(
  final KStream<K, V1> other,
  final ValueJoiner<? super V, ? super V1, ? extends R> joiner,
  final JoinWindows windows,
  final Joined<K, V, V1> joined,
  final KStreamImplJoin join)
----

`doJoin`...FIXME

NOTE: `doJoin` is used when...FIXME

=== [[transformValues]] Transforming Values with State -- `transformValues` Method

[source, java]
----
KStream<K, V1> transformValues(
  final ValueTransformerSupplier<? super V, ? extends V1> valueTransformerSupplier,
  final String... stateStoreNames)
KStream<K, VR> transformValues(
  final ValueTransformerWithKeySupplier<? super K, ? super V, ? extends VR> valueTransformerSupplier,
  final String... stateStoreNames)
----

NOTE: `transformValues` is part of link:kafka-streams-KStream.adoc#transformValues[KStream Contract] for a stateful record-by-record value transformation.

`transformValues` link:kafka-streams-AbstractStream.adoc#toInternalValueTransformerSupplier[converts ValueTransformerSupplier or ValueTransformerWithKeySupplier to InternalValueTransformerWithKeySupplier] followed by the internal <<transformValues-private, transformValues>>.

`transformValues` reports a `NullPointerException` when either `ValueTransformerSupplier` or `ValueTransformerWithKeySupplier` is `null`.

=== [[process]] `process` Method

[source, java]
----
void process(
  final ProcessorSupplier<? super K, ? super V> processorSupplier,
  final String... stateStoreNames)
----

NOTE: `process` is part of link:kafka-streams-KStream.adoc#process[KStream Contract] for...FIXME

`process`...FIXME

=== [[transform]] Stateful Record Transformation -- `transform` Operator

[source, java]
----
KStream<K1, V1> transform(
  final TransformerSupplier<? super K, ? super V, KeyValue<K1, V1>> transformerSupplier,
  final String... stateStoreNames)
----

NOTE: `transform` is part of link:kafka-streams-KStream.adoc#transform[KStream Contract] to...FIXME.

`transform` requests <<builder, InternalStreamsBuilder>> for a new processor name with *KSTREAM-TRANSFORM* prefix.

`transform` then creates a new `KStreamTransform` (for the input `transformerSupplier`) and requests `InternalTopologyBuilder` to link:kafka-streams-InternalTopologyBuilder.adoc#addProcessor[register] a new processor supplier under the name.

NOTE: `transform` uses <<builder, InternalStreamsBuilder>> to access the current link:kafka-streams-InternalStreamsBuilder.adoc#internalTopologyBuilder[InternalTopologyBuilder].

`transform` requests `InternalTopologyBuilder` to link:kafka-streams-InternalTopologyBuilder.adoc#connectProcessorAndStateStores[connect the processor supplier with state stores] if specified.

In the end, `transform` creates a new <<creating-instance, KStreamImpl>> for the processor name and <<repartitionRequired, repartitionRequired>> flag turned on.

`transform` reports a `NullPointerException` when `transformerSupplier` is `null`.

=== [[mapValues]] Registering Processor Node with KStreamMapValues Processor Supplier and KSTREAM-MAPVALUES Prefix -- `mapValues` Operator

[source, java]
----
<V1> KStream<K, V1> mapValues(final ValueMapper<? super V, ? extends V1> mapper)
----

NOTE: `mapValues` is part of link:kafka-streams-KStream.adoc#mapValues[KStream Contract] to...FIXME.

`mapValues` creates a new `KStreamImpl` for a new processor (with the current <<builder, InternalStreamsBuilder>>, <<sourceNodes, source nodes>> and <<repartitionRequired, repartitionRequired>> flag).

Internally, `mapValues` requests <<builder, InternalStreamsBuilder>> for a new processor name with *KSTREAM-MAPVALUES* prefix and link:kafka-streams-InternalTopologyBuilder.adoc#addProcessor[registers] a `KStreamMapValues` processor supplier under the name.

NOTE: `mapValues` uses <<builder, InternalStreamsBuilder>> to access the current link:kafka-streams-InternalStreamsBuilder.adoc#internalTopologyBuilder[InternalTopologyBuilder].

=== [[through]] `through` Operator

[source, java]
----
KStream<K, V> through(final String topic) // <1>
KStream<K, V> through(final String topic, final Produced<K, V> produced)
----
<1> Calls the other `to` with `Produced` of `nulls`

NOTE: `through` is part of link:kafka-streams-KStream.adoc#through[KStream Contract] to...FIXME.

`through`...FIXME

=== [[print]] Registering Processor Node with KStreamPrint Processor Supplier and KSTREAM-PRINTER Prefix -- `print` Operator

[source, java]
----
void print(final Printed<K, V> printed)
----

NOTE: `print` is part of link:kafka-streams-KStream.adoc#print[KStream Contract] to...FIXME.

`print` creates a `PrintedInternal` for the input link:kafka-streams-Printed.adoc[Printed].

`print` requests <<builder, InternalStreamsBuilder>> for a new processor name with *KSTREAM-PRINTER* prefix and link:kafka-streams-InternalTopologyBuilder.adoc#addProcessor[registers] a `KStreamPrint` (with `PrintForeachAction`) processor supplier under the name.

NOTE: `print` uses <<builder, InternalStreamsBuilder>> to access the current link:kafka-streams-InternalStreamsBuilder.adoc#internalTopologyBuilder[InternalTopologyBuilder].

=== [[to]] Registering Sink Node (with KSTREAM-SINK Prefix) -- `to` Operator

[source, java]
----
void to(final String topic) // <1>
void to(final String topic, final Produced<K, V> produced)
----
<1> Calls the other `to` with `Produced` of `nulls`

NOTE: `to` is part of link:kafka-streams-KStream.adoc#to[KStream Contract] to...FIXME.

`to` merely passes the call on to the internal <<to-internal, to>> with a new `ProducedInternal` for the input link:kafka-streams-Produced.adoc[Produced].

=== [[to-internal]] Registering Sink Node with KSTREAM-SINK Prefix -- `to` Internal Method

[source, java]
----
void to(final String topic, final ProducedInternal<K, V> produced)
----

`to` requests the <<builder, InternalStreamsBuilder>> for a new processor name with *KSTREAM-SINK* prefix.

NOTE: `to` uses the input `ProducedInternal` to access the `key` and `value` serializers, and the link:kafka-streams-StreamPartitioner.adoc[StreamPartitioner].

`to` requests the link:kafka-streams-AbstractStream.adoc#builder[InternalStreamsBuilder] for the link:kafka-streams-InternalStreamsBuilder.adoc#internalTopologyBuilder[InternalTopologyBuilder] and requests it to link:kafka-streams-InternalTopologyBuilder.adoc#addSink[register a new sink node] under the new processor name.

NOTE: `to` uses <<builder, InternalStreamsBuilder>> to access the current link:kafka-streams-InternalStreamsBuilder.adoc#internalTopologyBuilder[InternalTopologyBuilder].

NOTE: `to` uses link:kafka-streams-WindowedStreamPartitioner.adoc[WindowedStreamPartitioner] when the input `ProducedInternal` defines no link:kafka-streams-StreamPartitioner.adoc[StreamPartitioner] and uses `WindowedSerializer` for the key serializer.

NOTE: `to` is used in <<to, to>> and <<through, through>> operators.

=== [[repartitionForJoin]] `repartitionForJoin` Internal Method

[source, scala]
----
KStreamImpl<K, V> repartitionForJoin(
  final Serde<K> keySerde,
  final Serde<V> valSerde)
----

`repartitionForJoin`...FIXME

NOTE: `repartitionForJoin` is used when...FIXME

=== [[creating-instance]] Creating KStreamImpl Instance

`KStreamImpl` takes the following when created:

* [[builder]] link:kafka-streams-InternalStreamsBuilder.adoc[InternalStreamsBuilder] that created the `KStreamImpl`
* [[name]] Name of the stream processor node
* [[sourceNodes]] Source nodes
* [[repartitionRequired]] Flag whether repartitioning is required or not

`KStreamImpl` initializes the <<internal-registries, internal registries and counters>>.

=== [[transformValues-private]] Transforming Values with State -- `transformValues` Internal Method

[source, java]
----
private <VR> KStream<K, VR> transformValues(
  final InternalValueTransformerWithKeySupplier<? super K, ? super V, ? extends VR> internalValueTransformerWithKeySupplier,
  final String... stateStoreNames)
----

`transformValues` requests <<builder, InternalStreamsBuilder>> for a new processor name with *KSTREAM-TRANSFORMVALUES* prefix.

`transformValues` then creates a new `KStreamTransformValues` (for the input `internalValueTransformerWithKeySupplier`) and requests `InternalTopologyBuilder` to link:kafka-streams-InternalTopologyBuilder.adoc#addProcessor[register] a new processor supplier under the name.

NOTE: `transformValues` uses <<builder, InternalStreamsBuilder>> to access the current link:kafka-streams-InternalStreamsBuilder.adoc#internalTopologyBuilder[InternalTopologyBuilder].

`transformValues` requests `InternalTopologyBuilder` to link:kafka-streams-InternalTopologyBuilder.adoc#connectProcessorAndStateStores[connect the processor supplier with state stores] if specified.

In the end, `transformValues` creates a new <<creating-instance, KStreamImpl>> for the processor name.

NOTE: `transformValues` is used when `KStreamImpl` is requested to <<transformValues, transformValues>>.

=== [[createReparitionedSource]] `createReparitionedSource` Static Method

[source, java]
----
String createReparitionedSource(
  final InternalStreamsBuilder builder,
  final Serde<K1> keySerde,
  final Serde<V1> valSerde,
  final String topicNamePrefix,
  final String name)
----

`createReparitionedSource` requests the input `InternalStreamsBuilder` for the link:kafka-streams-InternalStreamsBuilder.adoc#internalTopologyBuilder[InternalTopologyBuilder] and does the following:

* Requests the `InternalTopologyBuilder` to link:kafka-streams-InternalTopologyBuilder.adoc#addInternalTopic[addInternalTopic] with the topic name as the input `topicNamePrefix` (if defined) or the input `name` and `-repartition` suffix

* Requests the `InternalStreamsBuilder` for a link:kafka-streams-InternalStreamsBuilder.adoc#newProcessorName[new processor name] with `KSTREAM-FILTER-` prefix and requests the `InternalTopologyBuilder` to link:kafka-streams-InternalTopologyBuilder.adoc#addProcessor[addProcessor] with the new processor name and a new `KStreamFilter` (that filters out `null` keys) and the `name` predecessor

* Requests the `InternalStreamsBuilder` for a link:kafka-streams-InternalStreamsBuilder.adoc#newProcessorName[new processor name] with `KSTREAM-SINK-` prefix and requests the `InternalTopologyBuilder` to link:kafka-streams-InternalTopologyBuilder.adoc#addSink[add a sink node] with the new processor name, the repartition topic and the new `KStreamFilter` as a predecessor

* Requests the `InternalStreamsBuilder` for a link:kafka-streams-InternalStreamsBuilder.adoc#newProcessorName[new processor name] with `KSTREAM-SOURCE-` prefix (aka `sourceName`) and requests the `InternalTopologyBuilder` to link:kafka-streams-InternalTopologyBuilder.adoc#addSource[add a source node] with the new processor name, a link:kafka-streams-FailOnInvalidTimestamp.adoc[FailOnInvalidTimestamp] and the repartition topic

In the end, `createReparitionedSource` returns the source name.

[source, scala]
----
// CAUTION: FIXME Example
----

[NOTE]
====
`createReparitionedSource` is used when:

* `GroupedStreamAggregateBuilder` is requested to link:kafka-streams-GroupedStreamAggregateBuilder.adoc#repartitionIfRequired[repartitionIfRequired]

* `KGroupedStreamImpl` is requested to link:kafka-streams-KGroupedStreamImpl.adoc#repartitionIfRequired[repartitionIfRequired]

* `KStreamImpl` is requested to <<repartitionForJoin, repartitionForJoin>>
====
