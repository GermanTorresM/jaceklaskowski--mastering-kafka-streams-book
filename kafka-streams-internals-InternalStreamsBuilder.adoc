== [[InternalStreamsBuilder]] InternalStreamsBuilder

`InternalStreamsBuilder` is an internal entity that <<kafka-streams-StreamsBuilder.adoc#, StreamsBuilder>> (of <<kafka-streams-streams-dsl.adoc#, Streams DSL -- High-Level Stream Processing DSL>>) uses to <<buildAndOptimizeTopology, build a topology>> by adding nodes to the <<root, stream graph>> using the high-level stream operators.

`InternalStreamsBuilder` is <<creating-instance, created>> exclusively for <<kafka-streams-StreamsBuilder.adoc#internalStreamsBuilder, StreamsBuilder>>.

.Creating InternalStreamsBuilder
image::images/kafka-streams-InternalStreamsBuilder.png[align="center"]

[[creating-instance]]
[[internalTopologyBuilder]]
`InternalStreamsBuilder` takes a <<kafka-streams-internals-InternalTopologyBuilder.adoc#, InternalTopologyBuilder>> to be created.

[source, scala]
----
import org.apache.kafka.streams.processor.internals.InternalTopologyBuilder
val intTopologyBuilder = new InternalTopologyBuilder

import org.apache.kafka.streams.kstream.internals.InternalStreamsBuilder
val intStreamsBuilder = new InternalStreamsBuilder(intTopologyBuilder)
----

[[root]]
`InternalStreamsBuilder` manages a <<kafka-streams-internals-StreamsGraphNode.adoc#, StreamsGraphNode>> as the *root node* (of the <<buildAndOptimizeTopology, topology to build>>). Every time `InternalStreamsBuilder` is requested to add a <<stream, stream>>, a <<table, table>>, a <<globalTable, global table>>, a <<addStateStore, state store>> or a <<addGlobalStore, global state store>> the root node <<addGraphNode, gets a corresponding child node added>>. Once the topology is of a proper structure, `InternalStreamsBuilder` can simply be requested to <<buildAndOptimizeTopology, build it (with optional optimizations applied)>>.

[source, scala]
----
import org.apache.kafka.streams.kstream.internals.InternalStreamsBuilder
assert(intStreamsBuilder.isInstanceOf[InternalStreamsBuilder])

val topics = Seq("input")
import org.apache.kafka.streams.kstream.internals.ConsumedInternal
val intConsumed = new ConsumedInternal[String, String]()
import scala.collection.JavaConversions._
// Add a new graph node (stream) to the root node
intStreamsBuilder.stream(topics, intConsumed)

intStreamsBuilder.buildAndOptimizeTopology

val root = intStreamsBuilder.root
import org.apache.kafka.streams.kstream.internals.graph.StreamsGraphNode
assert(root.isInstanceOf[StreamsGraphNode])
assert(root.children.size == 1)

// Let's explore what we built

val streamSourceNode = root.children.head
println(streamSourceNode)
/**
StreamSourceNode{topicNames=[input], topicPattern=null, consumedInternal=org.apache.kafka.streams.kstream.internals.ConsumedInternal@e1781} StreamsGraphNode{nodeName='KSTREAM-SOURCE-0000000000', buildPriority=0, hasWrittenToTopology=true, keyChangingOperation=false, valueChangingOperation=false, mergeNode=false, parentNodes=[root]}
*/

println(intTopologyBuilder.describe)
/**
Topologies:
   Sub-topology: 0
    Source: KSTREAM-SOURCE-0000000000 (topics: [input])
      --> none
*/
----

[[InternalNameProvider]]
`InternalStreamsBuilder` is an <<kafka-streams-internals-InternalNameProvider.adoc#, InternalNameProvider>> and can be requested for a name for new <<newProcessorName, processors>> and <<newStoreName, stores>>.

[[index]]
`InternalStreamsBuilder` uses `index` counter that starts at `0` and is incremented every time a new name for a <<newProcessorName, processor>> or a <<newStoreName, store>> is requested. That makes all names unique and sources and stores uniquely identified by name.

[[logging]]
[TIP]
====
Enable `ALL` logging level for `org.apache.kafka.streams.kstream.internals.InternalStreamsBuilder` logger to see what happens inside.

Add the following line to `log4j.properties`:

```
log4j.logger.org.apache.kafka.streams.kstream.internals.InternalStreamsBuilder=ALL
```

Refer to <<kafka-logging.adoc#log4j.properties, Application Logging Using log4j>>.
====

=== [[addStateStore]] Adding State Store to Topology -- `addStateStore` Method

[source, java]
----
void addStateStore(
  StoreBuilder builder)
----

`addStateStore` creates a <<kafka-streams-internals-StateStoreNode.adoc#, StateStoreNode>> (with the given <<kafka-streams-StoreBuilder.adoc#, StoreBuilder>>) and <<addGraphNode, adds it>> to the <<root, root>> node.

NOTE: `addStateStore` is used exclusively when `StreamsBuilder` is requested to <<kafka-streams-StreamsBuilder.adoc#addStateStore, add a state store to a topology>>.

=== [[stream]] Adding Stream to Topology (and Creating KStream) -- `stream` Method

[source, java]
----
KStream<K, V> stream(
  Collection<String> topics,
  ConsumedInternal<K, V> consumed)
KStream<K, V> stream(
  Pattern topicPattern,
  ConsumedInternal<K, V> consumed)
----

`stream` <<newProcessorName, creates a new processor name>> with <<kafka-streams-internals-KStreamImpl.adoc#SOURCE_NAME, KSTREAM-SOURCE>> prefix.

`stream` creates a new <<kafka-streams-internals-StreamSourceNode.adoc#, StreamSourceNode>> and <<addGraphNode, adds it>> to the <<root, root>> node.

In the end, `stream` returns a new instance of <<kafka-streams-internals-KStreamImpl.adoc#, KStreamImpl>> (with the new processor name that is also used as the name of the single source node and the <<kafka-streams-internals-KStreamImpl.adoc#repartitionRequired, repartitionRequired>> flag off).

[source, scala]
----
import org.apache.kafka.streams.processor.internals.InternalTopologyBuilder
val internalTopologyBuilder = new InternalTopologyBuilder()

import org.apache.kafka.streams.kstream.internals.InternalStreamsBuilder
val internalStreamsBuilder = new InternalStreamsBuilder(internalTopologyBuilder)

val topics = Seq("input")
import org.apache.kafka.streams.kstream.internals.ConsumedInternal
val consumed = new ConsumedInternal[String, String]()
import collection.JavaConverters._
val kstream = internalStreamsBuilder.stream(topics.asJava, consumed)
scala> :type kstream
org.apache.kafka.streams.kstream.KStream[String,String]

import org.apache.kafka.streams.kstream.internals.KStreamImpl
assert(kstream.isInstanceOf[KStreamImpl[String, String]])
----

[NOTE]
====
`stream` is used when:

* `StreamsBuilder` is requested to <<kafka-streams-StreamsBuilder.adoc#stream, stream>>

* `KStreamImpl` is requested to <<kafka-streams-internals-KStreamImpl.adoc#through, through>>
====

=== [[table]] Adding Table to Topology (and Creating KTable) -- `table` Method

[source, java]
----
KTable<K, V> table(
  String topic,
  ConsumedInternal<K, V> consumed,
  MaterializedInternal<K, V, KeyValueStore<Bytes, byte[]>> materialized)
----

`table`...FIXME

NOTE: `table` is used exclusively when `StreamsBuilder` is requested to <<kafka-streams-StreamsBuilder.adoc#table, add a table to a topology>>.

=== [[addGlobalStore]] Adding Global State Store to Topology -- `addGlobalStore` Method

[source, java]
----
void addGlobalStore(
  StoreBuilder<KeyValueStore> storeBuilder,
  String topic,
  ConsumedInternal consumed,
  ProcessorSupplier stateUpdateSupplier)
void addGlobalStore(
  StoreBuilder<KeyValueStore> storeBuilder,
  String sourceName,
  String topic,
  ConsumedInternal consumed,
  String processorName,
  ProcessorSupplier stateUpdateSupplier)
----

`addGlobalStore`...FIXME

NOTE: `addGlobalStore` is used exclusively when `StreamsBuilder` is requested to <<kafka-streams-StreamsBuilder.adoc#addGlobalStore, addGlobalStore>>.

=== [[globalTable]] Adding Global Table to Topology (and Creating GlobalKTable) -- `globalTable` Method

[source, java]
----
GlobalKTable<K, V> globalTable(
  String topic,
  ConsumedInternal<K, V> consumed,
  MaterializedInternal<K, V, KeyValueStore<Bytes, byte[]>> materialized)
----

`globalTable` creates a new <<kafka-streams-internals-GlobalKTableImpl.adoc#, GlobalKTableImpl>>.

Internally, `globalTable` requests the `MaterializedInternal` to <<kafka-streams-Materialized.adoc#withLoggingDisabled, disable logging>> (regardless whether it was enabled initially or not).

NOTE: `GlobalKTables` use state stores with logging disabled.

`globalTable` then creates a <<kafka-streams-internals-KeyValueStoreMaterializer.adoc#, KeyValueStoreMaterializer>> (with the input `MaterializedInternal` with logging disabled) and requests it to <<kafka-streams-internals-KeyValueStoreMaterializer.adoc#materialize, materialize>> (and create a <<kafka-streams-StoreBuilder.adoc#, StoreBuilder>>).

`globalTable` creates a `TableSourceNode` (with the `StoreBuilder`, the <<newProcessorName, source processor name>> with `KSTREAM-SOURCE-` prefix, and `isGlobalKTable` flag on)

`globalTable` <<addGraphNode, adds>> the `TableSourceNode` to the <<root, root>> node.

In the end, `globalTable` creates a <<kafka-streams-internals-GlobalKTableImpl.adoc#, GlobalKTableImpl>> (with a new <<kafka-streams-internals-KTableSourceValueGetterSupplier.adoc#, KTableSourceValueGetterSupplier>> and the queryable flag of the `MaterializedInternal`).

NOTE: `globalTable` is used exclusively when `StreamsBuilder` is requested to <<kafka-streams-StreamsBuilder.adoc#globalTable, add a global table to a topology>>.

=== [[newProcessorName]] New Unique Processor Name -- `newProcessorName` Method

[source, java]
----
String newProcessorName(
  String prefix)
----

NOTE: `newProcessorName` is part of link:kafka-streams-internals-InternalNameProvider.adoc#newProcessorName[InternalNameProvider Contract] to create a new unique name for a link:kafka-streams-internals-ProcessorNode.adoc[processor].

`newProcessorName` simply takes the input `prefix` followed by the <<index, index>>.

NOTE: The <<index, index>> counter is what makes it bound to a `InternalStreamsBuilder`.

[source, scala]
----
import org.apache.kafka.streams.kstream.internals.InternalStreamsBuilder
import org.apache.kafka.streams.processor.internals.InternalTopologyBuilder
val newBuilder = new InternalStreamsBuilder(new InternalTopologyBuilder)

val name = newBuilder.newProcessorName("PREFIX")
scala> println(name)
PREFIX0000000001
----

=== [[newStoreName]] New Unique Store Name -- `newStoreName` Method

[source, java]
----
String newStoreName(
  String prefix)
----

NOTE: `newStoreName` is part of link:kafka-streams-internals-InternalNameProvider.adoc#newStoreName[InternalNameProvider Contract] to create a new unique name for a link:kafka-streams-StateStore.adoc[state store].

`newStoreName` simply concatenates the input `prefix`, `STATE-STORE-` and the <<index, index>>.

NOTE: The <<index, index>> counter is what makes it bound to a `InternalStreamsBuilder`.

[source, scala]
----
import org.apache.kafka.streams.kstream.internals.InternalStreamsBuilder
import org.apache.kafka.streams.processor.internals.InternalTopologyBuilder
val newBuilder = new InternalStreamsBuilder(new InternalTopologyBuilder)

val name = newBuilder.newStoreName("PREFIX")
scala> println(name)
PREFIXSTATE-STORE-0000000001
----

=== [[addGraphNode]] Adding Child Node -- `addGraphNode` Method

[source, java]
----
void addGraphNode(
  StreamsGraphNode parent,
  StreamsGraphNode child)
void addGraphNode(
  Collection<StreamsGraphNode> parents,
  StreamsGraphNode child)
----

`addGraphNode` simply requests the input <<kafka-streams-internals-StreamsGraphNode.adoc#, StreamsGraphNode>> to <<kafka-streams-internals-StreamsGraphNode.adoc#addChild, add the given child node>>.

In the end, `addGraphNode` <<maybeAddNodeForOptimizationMetadata, maybeAddNodeForOptimizationMetadata>>.

NOTE: `addGraphNode` is used in _many places_ in <<kafka-streams-internals-GroupedStreamAggregateBuilder.adoc#, GroupedStreamAggregateBuilder>>, <<kafka-streams-internals-InternalStreamsBuilder.adoc#, InternalStreamsBuilder>>, <<kafka-streams-internals-KGroupedTableImpl.adoc#, KGroupedTableImpl>>, <<kafka-streams-internals-KStreamImpl.adoc#, KStreamImpl>>, <<kafka-streams-internals-KStreamImpl-KStreamImplJoin.adoc#, KStreamImplJoin>>, and <<kafka-streams-internals-KTableImpl.adoc#, KTableImpl>>.

=== [[buildAndOptimizeTopology]] Building Topology (with Optional Optimizations) -- `buildAndOptimizeTopology` Method

[source, java]
----
void buildAndOptimizeTopology() // <1>
void buildAndOptimizeTopology(
  Properties props)
----
<1> For testing only; Uses `null` for the `Properties`

`buildAndOptimizeTopology` does <<maybePerformOptimizations, maybePerformOptimizations>> (with the given `Properties`).

`buildAndOptimizeTopology`...FIXME

NOTE: `buildAndOptimizeTopology` is used exclusively when `StreamsBuilder` is requested to <<kafka-streams-StreamsBuilder.adoc#build, build a topology>>.

=== [[maybeAddNodeForOptimizationMetadata]] `maybeAddNodeForOptimizationMetadata` Internal Method

[source, java]
----
void maybeAddNodeForOptimizationMetadata(
  StreamsGraphNode node)
----

`maybeAddNodeForOptimizationMetadata`...FIXME

NOTE: `maybeAddNodeForOptimizationMetadata` is used exclusively when `InternalStreamsBuilder` is requested to <<addGraphNode, adding a child node>>.

=== [[maybePerformOptimizations]] `maybePerformOptimizations` Internal Method

[source, java]
----
void maybePerformOptimizations(
  Properties props)
----

`maybePerformOptimizations`...FIXME

NOTE: `maybePerformOptimizations` is used exclusively when `InternalStreamsBuilder` is requested to <<buildAndOptimizeTopology, build a topology (with optional optimizations)>>.

=== [[getKeyChangingParentNode]] `getKeyChangingParentNode` Internal Method

[source, java]
----
StreamsGraphNode getKeyChangingParentNode(
  StreamsGraphNode repartitionNode)
----

`getKeyChangingParentNode`...FIXME

NOTE: `getKeyChangingParentNode` is used exclusively when `InternalStreamsBuilder` is requested to <<maybeAddNodeForOptimizationMetadata, maybeAddNodeForOptimizationMetadata>>.

=== [[maybeOptimizeRepartitionOperations]] `maybeOptimizeRepartitionOperations` Internal Method

[source, java]
----
void maybeOptimizeRepartitionOperations()
----

`maybeOptimizeRepartitionOperations`...FIXME

NOTE: `maybeOptimizeRepartitionOperations` is used exclusively when `InternalStreamsBuilder` is requested to <<maybePerformOptimizations, maybePerformOptimizations>>.

=== [[createRepartitionNode]] `createRepartitionNode` Internal Method

[source, java]
----
OptimizableRepartitionNode createRepartitionNode(
  String repartitionTopicName,
  Serde keySerde,
  Serde valueSerde)
----

`createRepartitionNode`...FIXME

NOTE: `createRepartitionNode` is used when...FIXME

=== [[findParentNodeMatching]] `findParentNodeMatching` Internal Method

[source, java]
----
StreamsGraphNode findParentNodeMatching(
  StreamsGraphNode startSeekingNode,
  Predicate<StreamsGraphNode> parentNodePredicate)
----

`findParentNodeMatching`...FIXME

NOTE: `findParentNodeMatching` is used when...FIXME

=== [[getFirstRepartitionTopicName]] `getFirstRepartitionTopicName` Internal Method

[source, java]
----
String getFirstRepartitionTopicName(
  Collection<OptimizableRepartitionNode> repartitionNodes)
----

`getFirstRepartitionTopicName`...FIXME

NOTE: `getFirstRepartitionTopicName` is used when...FIXME

=== [[getRepartitionSerdes]] `getRepartitionSerdes` Internal Method

[source, java]
----
GroupedInternal getRepartitionSerdes(
  Collection<OptimizableRepartitionNode> repartitionNodes)
----

`getRepartitionSerdes`...FIXME

NOTE: `getRepartitionSerdes` is used when...FIXME

=== [[maybeUpdateKeyChangingRepartitionNodeMap]] `maybeUpdateKeyChangingRepartitionNodeMap` Internal Method

[source, java]
----
void maybeUpdateKeyChangingRepartitionNodeMap()
----

`maybeUpdateKeyChangingRepartitionNodeMap`...FIXME

NOTE: `maybeUpdateKeyChangingRepartitionNodeMap` is used when...FIXME

=== [[optimizeKTableSourceTopics]] `optimizeKTableSourceTopics` Internal Method

[source, java]
----
void optimizeKTableSourceTopics()
----

`optimizeKTableSourceTopics`...FIXME

NOTE: `optimizeKTableSourceTopics` is used when...FIXME
