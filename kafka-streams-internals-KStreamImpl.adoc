== [[KStreamImpl]] KStreamImpl

`KStreamImpl` is a concrete <<kafka-streams-AbstractStream.adoc#, stream>> and the one and only <<kafka-streams-KStream.adoc#, KStream>>.

`KStreamImpl` is <<creating-instance, created>> every time a transformation is executed and when...FIXME

[[internal-registries]]
.KStreamImpl's Internal Properties (e.g. Registries, Counters and Flags)
[cols="1,2",options="header",width="100%"]
|===
| Name
| Description

| [[defaultKeyValueMapper]] `defaultKeyValueMapper`
| link:kafka-streams-KeyValueMapper.adoc[KeyValueMapper] that simply concatenates the key and the value of a record when link:kafka-streams-KeyValueMapper.adoc#apply[executed] (i.e. applied to a record stream)
|===

=== [[doStreamTableJoin]] `doStreamTableJoin` Internal Method

[source, java]
----
<V1, R> KStream<K, R> doStreamTableJoin(
  final KTable<K, V1> other,
  final ValueJoiner<? super V, ? super V1, ? extends R> joiner,
  final boolean leftJoin)
----

`doStreamTableJoin`...FIXME

NOTE: `doStreamTableJoin` is used when...FIXME

=== [[doJoin]] `doJoin` Internal Method

[source, java]
----
<V1, R> KStream<K, R> doJoin(
  final KStream<K, V1> other,
  final ValueJoiner<? super V, ? super V1, ? extends R> joiner,
  final JoinWindows windows,
  final Joined<K, V, V1> joined,
  final KStreamImplJoin join)
----

`doJoin`...FIXME

NOTE: `doJoin` is used when `KStreamImpl` is requested to <<join, join>>, <<outerJoin, outerJoin>> and <<leftJoin, leftJoin>>.

=== [[transformValues]] Transforming Values with Optional State -- `transformValues` Method

[source, java]
----
KStream<K, V1> transformValues(
  final ValueTransformerSupplier<? super V, ? extends V1> valueTransformerSupplier,
  final String... stateStoreNames)
KStream<K, VR> transformValues(
  final ValueTransformerWithKeySupplier<? super K, ? super V, ? extends VR> valueTransformerSupplier,
  final String... stateStoreNames)
----

NOTE: `transformValues` is part of link:kafka-streams-KStream.adoc#transformValues[KStream Contract] for a stateful record-by-record value transformation.

`transformValues` link:kafka-streams-AbstractStream.adoc#toInternalValueTransformerSupplier[converts ValueTransformerSupplier or ValueTransformerWithKeySupplier to InternalValueTransformerWithKeySupplier] followed by the internal <<transformValues-private, transformValues>>.

`transformValues` reports a `NullPointerException` when either `ValueTransformerSupplier` or `ValueTransformerWithKeySupplier` is `null`.

=== [[process]] `process` Method

[source, java]
----
void process(
  final ProcessorSupplier<? super K, ? super V> processorSupplier,
  final String... stateStoreNames)
----

NOTE: `process` is part of link:kafka-streams-KStream.adoc#process[KStream Contract] for...FIXME

`process`...FIXME

=== [[transform]] Transforming Record Into Zero or More Output Records with State (Stateful Transformation) -- `transform` Operator

[source, java]
----
KStream<K1, V1> transform(
  final TransformerSupplier<? super K, ? super V, KeyValue<K1, V1>> transformerSupplier,
  final String... stateStoreNames)
----

NOTE: `transform` is part of <<kafka-streams-KStream.adoc#transform, KStream API>> to transform a record into zero or more output records with state.

`transform` requests <<builder, InternalStreamsBuilder>> for a new processor name with *KSTREAM-TRANSFORM* prefix.

`transform` then creates a new `KStreamTransform` (for the input `transformerSupplier`) and requests `InternalTopologyBuilder` to link:kafka-streams-InternalTopologyBuilder.adoc#addProcessor[register] a new processor supplier under the name.

NOTE: `transform` uses <<builder, InternalStreamsBuilder>> to access the current link:kafka-streams-InternalStreamsBuilder.adoc#internalTopologyBuilder[InternalTopologyBuilder].

`transform` requests `InternalTopologyBuilder` to link:kafka-streams-InternalTopologyBuilder.adoc#connectProcessorAndStateStores[connect the processor supplier with state stores] if specified.

In the end, `transform` creates a new <<creating-instance, KStreamImpl>> for the processor name and <<repartitionRequired, repartitionRequired>> flag turned on.

`transform` reports a `NullPointerException` when `transformerSupplier` is `null`.

=== [[mapValues]] Registering Processor Node with KStreamMapValues Processor Supplier and KSTREAM-MAPVALUES Prefix -- `mapValues` Operator

[source, java]
----
<V1> KStream<K, V1> mapValues(final ValueMapper<? super V, ? extends V1> mapper)
----

NOTE: `mapValues` is part of link:kafka-streams-KStream.adoc#mapValues[KStream Contract] to...FIXME.

`mapValues` creates a new `KStreamImpl` for a new processor (with the current <<builder, InternalStreamsBuilder>>, <<sourceNodes, source nodes>> and <<repartitionRequired, repartitionRequired>> flag).

Internally, `mapValues` requests <<builder, InternalStreamsBuilder>> for a new processor name with *KSTREAM-MAPVALUES* prefix and link:kafka-streams-InternalTopologyBuilder.adoc#addProcessor[registers] a `KStreamMapValues` processor supplier under the name.

NOTE: `mapValues` uses <<builder, InternalStreamsBuilder>> to access the current link:kafka-streams-InternalStreamsBuilder.adoc#internalTopologyBuilder[InternalTopologyBuilder].

=== [[through]] `through` Operator

[source, java]
----
KStream<K, V> through(final String topic) // <1>
KStream<K, V> through(final String topic, final Produced<K, V> produced)
----
<1> Calls the other `to` with `Produced` of `nulls`

NOTE: `through` is part of link:kafka-streams-KStream.adoc#through[KStream Contract] to...FIXME.

`through`...FIXME

=== [[print]] Registering Processor Node with KStreamPrint Processor Supplier and KSTREAM-PRINTER Prefix -- `print` Operator

[source, java]
----
void print(final Printed<K, V> printed)
----

NOTE: `print` is part of link:kafka-streams-KStream.adoc#print[KStream Contract] to...FIXME.

`print` creates a `PrintedInternal` for the input link:kafka-streams-Printed.adoc[Printed].

`print` requests <<builder, InternalStreamsBuilder>> for a new processor name with *KSTREAM-PRINTER* prefix and link:kafka-streams-InternalTopologyBuilder.adoc#addProcessor[registers] a `KStreamPrint` (with `PrintForeachAction`) processor supplier under the name.

NOTE: `print` uses <<builder, InternalStreamsBuilder>> to access the current link:kafka-streams-InternalStreamsBuilder.adoc#internalTopologyBuilder[InternalTopologyBuilder].

=== [[to]] Registering Sink Node (with KSTREAM-SINK Prefix) -- `to` Operator

[source, java]
----
void to(final String topic) // <1>
void to(final String topic, final Produced<K, V> produced)
----
<1> Calls the other `to` with `Produced` of `nulls`

NOTE: `to` is part of link:kafka-streams-KStream.adoc#to[KStream Contract] to...FIXME.

`to` merely passes the call on to the internal <<to-internal, to>> with a new `ProducedInternal` for the input link:kafka-streams-Produced.adoc[Produced].

=== [[to-internal]] Registering Sink Node with KSTREAM-SINK Prefix -- `to` Internal Method

[source, java]
----
void to(final String topic, final ProducedInternal<K, V> produced)
----

`to` requests the <<builder, InternalStreamsBuilder>> for a new processor name with *KSTREAM-SINK* prefix.

NOTE: `to` uses the input `ProducedInternal` to access the `key` and `value` serializers, and the link:kafka-streams-StreamPartitioner.adoc[StreamPartitioner].

`to` requests the link:kafka-streams-AbstractStream.adoc#builder[InternalStreamsBuilder] for the link:kafka-streams-InternalStreamsBuilder.adoc#internalTopologyBuilder[InternalTopologyBuilder] and requests it to link:kafka-streams-InternalTopologyBuilder.adoc#addSink[register a new sink node] under the new processor name.

NOTE: `to` uses <<builder, InternalStreamsBuilder>> to access the current link:kafka-streams-InternalStreamsBuilder.adoc#internalTopologyBuilder[InternalTopologyBuilder].

NOTE: `to` uses link:kafka-streams-WindowedStreamPartitioner.adoc[WindowedStreamPartitioner] when the input `ProducedInternal` defines no link:kafka-streams-StreamPartitioner.adoc[StreamPartitioner] and uses `WindowedSerializer` for the key serializer.

NOTE: `to` is used in <<to, to>> and <<through, through>> operators.

=== [[repartitionForJoin]] `repartitionForJoin` Internal Method

[source, scala]
----
KStreamImpl<K, V> repartitionForJoin(
  final Serde<K> keySerde,
  final Serde<V> valSerde)
----

`repartitionForJoin`...FIXME

NOTE: `repartitionForJoin` is used when...FIXME

=== [[creating-instance]] Creating KStreamImpl Instance

`KStreamImpl` takes the following when created:

* [[builder]] link:kafka-streams-InternalStreamsBuilder.adoc[InternalStreamsBuilder] that created the `KStreamImpl`
* [[name]] Name of the source processor node
* [[sourceNodes]] Source nodes
* [[repartitionRequired]] Flag whether repartitioning is required or not

`KStreamImpl` initializes the <<internal-registries, internal registries and counters>>.

==== [[transformValues-private]] Transforming Values with State -- `transformValues` Internal Method

[source, java]
----
private <VR> KStream<K, VR> transformValues(
  final InternalValueTransformerWithKeySupplier<? super K, ? super V, ? extends VR> internalValueTransformerWithKeySupplier,
  final String... stateStoreNames)
----

`transformValues` requests <<builder, InternalStreamsBuilder>> for a new processor name with *KSTREAM-TRANSFORMVALUES* prefix.

`transformValues` then creates a new link:kafka-streams-KStreamTransformValues.adoc#creating-instance[KStreamTransformValues] (for the input `internalValueTransformerWithKeySupplier`) and requests `InternalTopologyBuilder` to link:kafka-streams-InternalTopologyBuilder.adoc#addProcessor[register] a new processor supplier under the name.

NOTE: `transformValues` uses <<builder, InternalStreamsBuilder>> to access the current link:kafka-streams-InternalStreamsBuilder.adoc#internalTopologyBuilder[InternalTopologyBuilder].

`transformValues` requests `InternalTopologyBuilder` to link:kafka-streams-InternalTopologyBuilder.adoc#connectProcessorAndStateStores[connect the processor supplier with state stores] if specified.

In the end, `transformValues` creates a new <<creating-instance, KStreamImpl>> for the processor name.

NOTE: `transformValues` is used exclusively when `KStreamImpl` is requested to <<transformValues, transformValues>>.

=== [[createReparitionedSource]] `createReparitionedSource` Static Method

[source, java]
----
String createReparitionedSource(
  final InternalStreamsBuilder builder,
  final Serde<K1> keySerde,
  final Serde<V1> valSerde,
  final String topicNamePrefix,
  final String name)
----

`createReparitionedSource` requests the input `InternalStreamsBuilder` for the link:kafka-streams-InternalStreamsBuilder.adoc#internalTopologyBuilder[InternalTopologyBuilder] and does the following:

* Requests the `InternalTopologyBuilder` to link:kafka-streams-InternalTopologyBuilder.adoc#addInternalTopic[addInternalTopic] with the topic name as the input `topicNamePrefix` (if defined) or the input `name` and `-repartition` suffix

* Requests the `InternalStreamsBuilder` for a link:kafka-streams-InternalStreamsBuilder.adoc#newProcessorName[new processor name] with `KSTREAM-FILTER-` prefix and requests the `InternalTopologyBuilder` to link:kafka-streams-InternalTopologyBuilder.adoc#addProcessor[addProcessor] with the new processor name and a new <<kafka-streams-internals-KStreamFilter.adoc#, KStreamFilter>> (that filters out `null` keys) and the `name` predecessor

* Requests the `InternalStreamsBuilder` for a link:kafka-streams-InternalStreamsBuilder.adoc#newProcessorName[new processor name] with `KSTREAM-SINK-` prefix and requests the `InternalTopologyBuilder` to link:kafka-streams-InternalTopologyBuilder.adoc#addSink[add a sink node] with the new processor name, the repartition topic and the new `KStreamFilter` as a predecessor

* Requests the `InternalStreamsBuilder` for a link:kafka-streams-InternalStreamsBuilder.adoc#newProcessorName[new processor name] with `KSTREAM-SOURCE-` prefix (aka `sourceName`) and requests the `InternalTopologyBuilder` to link:kafka-streams-InternalTopologyBuilder.adoc#addSource[add a source node] with the new processor name, a link:kafka-streams-FailOnInvalidTimestamp.adoc[FailOnInvalidTimestamp] and the repartition topic

In the end, `createReparitionedSource` returns the source name.

[source, scala]
----
// CAUTION: FIXME Example
----

[NOTE]
====
`createReparitionedSource` is used when:

* `GroupedStreamAggregateBuilder` is requested to <<kafka-streams-GroupedStreamAggregateBuilder.adoc#repartitionIfRequired, repartitionIfRequired>>

* `KStreamImpl` is requested to <<repartitionForJoin, repartitionForJoin>>
====

=== [[createWindowedStateStore]] `createWindowedStateStore` Internal Static Method

[source, java]
----
<K, V> StoreBuilder<WindowStore<K, V>> createWindowedStateStore(
  final JoinWindows windows,
  final Serde<K> keySerde,
  final Serde<V> valueSerde,
  final String storeName)
----

`createWindowedStateStore`...FIXME

NOTE: `createWindowedStateStore` is used exclusively when `KStreamImplJoin` is requested to <<kafka-streams-KStreamImplJoin.adoc#join, join>>.

=== [[groupBy]] `groupBy` Method

[source, java]
----
KGroupedStream<KR, V> groupBy(
  final KeyValueMapper<? super K, ? super V, KR> selector)
KGroupedStream<KR, V> groupBy(
  final KeyValueMapper<? super K, ? super V, KR> selector,
  final Grouped<KR, V> grouped)
----

NOTE: `groupBy` is part of the <<kafka-streams-KStream.adoc#groupBy, KStream Contract>> to...FIXME.

`groupBy`...FIXME

=== [[groupByKey]] `groupByKey` Method

[source, java]
----
KGroupedStream<K, V> groupByKey()
KGroupedStream<K, V> groupByKey(final Grouped<K, V> grouped)
----

NOTE: `groupByKey` is part of the <<kafka-streams-KStream.adoc#groupByKey, KStream Contract>> to...FIXME.

`groupByKey`...FIXME

=== [[filter]] `filter` Method

[source, java]
----
KStream<K, V> filter(final Predicate<? super K, ? super V> predicate)
----

NOTE: `filter` is part of the <<kafka-streams-KStream.adoc#filter, KStream Contract>> to...FIXME.

`filter`...FIXME

=== [[filterNot]] `filterNot` Method

[source, java]
----
KStream<K, V> filterNot(final Predicate<? super K, ? super V> predicate)
----

NOTE: `filterNot` is part of the <<kafka-streams-KStream.adoc#filterNot, KStream Contract>> to...FIXME.

`filterNot`...FIXME
