== [[Topology]] Topology -- Logical Processor Node Topology

`Topology` is an *directed acyclic graph of processors* (aka _DAG of stream processing nodes_) that represents the stream processing logic of a Kafka Streams application.

`Topology` is a logical representation of a <<kafka-streams-internals-ProcessorTopology.adoc#, ProcessorTopology>>.

`Topology` provides the <<operators, fluent API>> to <<creating-instance, create a processing topology>> of <<addStateStore, local>> and <<addGlobalStore, global>> state stores, <<addSource, sources>>, <<addProcessor, processors>> and <<addSink, sinks>>.

`Topology` can be <<creating-instance, created>> directly or indirectly using <<kafka-streams-streams-dsl.adoc#, Streams DSL -- High-Level Stream Processing DSL>>.

[[creating-instance]]
`Topology` takes no arguments when created.

[source, scala]
----
// Created directly
import org.apache.kafka.streams.Topology
val topology = new Topology

// Created using Streams DSL (StreamsBuilder API)
// Scala API for Kafka Streams
import org.apache.kafka.streams.scala._
import ImplicitConversions._
import Serdes._

val builder = new StreamsBuilder
val topology = builder.build
scala> :type topology
org.apache.kafka.streams.Topology
----

Once <<creating-instance, created>>, `Topology` can be extended with <<addSource, sources>>, <<addProcessor, processors>> (optionally <<connectProcessorAndStateStores, connected to one or more state stores>>), <<addSink, sinks>>, with <<addStateStore, local>> and <<addGlobalStore, global>> state stores.

[source, scala]
----
scala> :type topology
org.apache.kafka.streams.Topology

import org.apache.kafka.streams.state.Stores
val storeBuilder = Stores.keyValueStoreBuilder[String, String](
  Stores.inMemoryKeyValueStore("in-memory-key-value-store"),
  Serdes.String,
  Serdes.String)
  .withLoggingDisabled  // this is for a global table
val sourceName = "demo-source-processor"
val timestampExtractor = null
val keyDeserializer = Serdes.String.deserializer
val valueDeserializer = Serdes.String.deserializer
val topic = "demo-topic"
val processorName = "demo-processor-supplier"
import org.apache.kafka.streams.kstream.internals.KTableSource
val stateUpdateSupplier = new KTableSource[String, String]("store-name")
topology.addGlobalStore(
  storeBuilder,
  sourceName,
  timestampExtractor,
  keyDeserializer,
  valueDeserializer,
  topic,
  processorName,
  stateUpdateSupplier)
----

`Topology` can be <<describe, described>>.

[source, scala]
----
scala> :type topology
org.apache.kafka.streams.Topology

scala> println(topology.describe)
Topologies:
   Sub-topology: 0 for global store (will not generate tasks)
    Source: demo-source-processor (topics: [demo-topic])
      --> demo-processor-supplier
    Processor: demo-processor-supplier (stores: [in-memory-key-value-store])
      --> none
      <-- demo-source-processor
----

[[AutoOffsetReset]]
`Topology` defines *offset reset policy* (`AutoOffsetReset`) that can be one of the two possible values:

* [[EARLIEST]] `EARLIEST`
* [[LATEST]] `LATEST`

[[operators]]
.Topology API / Methods
[cols="1m,2",options="header",width="100%"]
|===
| Method
| Description

| addGlobalStore
a| [[addGlobalStore]]

[source, java]
----
Topology addGlobalStore(
  final StoreBuilder storeBuilder,
  final String sourceName,
  final Deserializer keyDeserializer,
  final Deserializer valueDeserializer,
  final String topic,
  final String processorName,
  final ProcessorSupplier stateUpdateSupplier)
Topology addGlobalStore(
  final StoreBuilder storeBuilder,
  final String sourceName,
  final TimestampExtractor timestampExtractor,
  final Deserializer keyDeserializer,
  final Deserializer valueDeserializer,
  final String topic,
  final String processorName,
  final ProcessorSupplier stateUpdateSupplier)
----

Adds a global <<kafka-streams-StateStore.adoc#, StateStore>> (with the <<kafka-streams-StoreBuilder.adoc#, StoreBuilder>>, <<kafka-streams-ProcessorSupplier.adoc#, ProcessorSupplier>> and optional <<kafka-streams-TimestampExtractor.adoc#, TimestampExtractor>>) to the topology.

| addProcessor
a| [[addProcessor]]

[source, java]
----
Topology addProcessor(
  final String name,
  final ProcessorSupplier supplier,
  final String... parentNames)
----

Adds a new <<kafka-streams-Processor.adoc#, processor node>> (using the <<kafka-streams-ProcessorSupplier.adoc#, ProcessorSupplier>>) to the topology.

| addSink
a| [[addSink]]

[source, java]
----
Topology addSink(
  final String name,
  final String topic,
  final Serializer<K> keySerializer,
  final Serializer<V> valueSerializer,
  final StreamPartitioner<? super K, ? super V> partitioner,
  final String... parentNames)
Topology addSink(
  final String name,
  final String topic,
  final Serializer<K> keySerializer,
  final Serializer<V> valueSerializer,
  final String... parentNames)
Topology addSink(
  final String name,
  final String topic,
  final StreamPartitioner<? super K, ? super V> partitioner,
  final String... parentNames)
Topology addSink(
  final String name,
  final String topic,
  final String... parentNames)
Topology addSink(
  final String name,
  final TopicNameExtractor<K, V> topicExtractor,
  final Serializer<K> keySerializer,
  final Serializer<V> valueSerializer,
  final StreamPartitioner<? super K, ? super V> partitioner,
  final String... parentNames)
Topology addSink(
  final String name,
  final TopicNameExtractor<K, V> topicExtractor,
  final Serializer<K> keySerializer,
  final Serializer<V> valueSerializer,
  final String... parentNames)
Topology addSink(
  final String name,
  final TopicNameExtractor<K, V> topicExtractor,
  final StreamPartitioner<? super K, ? super V> partitioner,
  final String... parentNames)
Topology addSink(
  final String name,
  final TopicNameExtractor<K, V> topicExtractor,
  final String... parentNames)
----

Adds a new <<kafka-streams-internals-SinkNode.adoc#, sink node>> (with the optional <<kafka-streams-TopicNameExtractor.adoc#, TopicNameExtractor>> and <<kafka-streams-StreamPartitioner.adoc#, StreamPartitioner>>) to the topology.

| addSource
a| [[addSource]]

[source, java]
----
Topology addSource(
  final AutoOffsetReset offsetReset,
  final String name,
  final Deserializer keyDeserializer,
  final Deserializer valueDeserializer,
  final Pattern topicPattern)
Topology addSource(
  final AutoOffsetReset offsetReset,
  final String name,
  final Deserializer keyDeserializer,
  final Deserializer valueDeserializer,
  final String... topics)
Topology addSource(
  final AutoOffsetReset offsetReset,
  final String name,
  final Pattern topicPattern)
Topology addSource(
  final AutoOffsetReset offsetReset,
  final String name,
  final String... topics)
Topology addSource(
  final AutoOffsetReset offsetReset,
  final String name,
  final TimestampExtractor timestampExtractor,
  final Deserializer keyDeserializer,
  final Deserializer valueDeserializer,
  final Pattern topicPattern)
Topology addSource(
  final AutoOffsetReset offsetReset,
  final String name,
  final TimestampExtractor timestampExtractor,
  final Deserializer keyDeserializer,
  final Deserializer valueDeserializer,
  final String... topics)
Topology addSource(
  final AutoOffsetReset offsetReset,
  final TimestampExtractor timestampExtractor,
  final String name,
  final Pattern topicPattern)
Topology addSource(
  final AutoOffsetReset offsetReset,
  final TimestampExtractor timestampExtractor,
  final String name,
  final String... topics)
Topology addSource(
  final String name,
  final Deserializer keyDeserializer,
  final Deserializer valueDeserializer,
  final Pattern topicPattern)
Topology addSource(
  final String name,
  final Deserializer keyDeserializer,
  final Deserializer valueDeserializer,
  final String... topics)
Topology addSource(
  final String name,
  final Pattern topicPattern)
Topology addSource(
  final String name,
  final String... topics)
Topology addSource(
  final TimestampExtractor timestampExtractor,
  final String name,
  final Pattern topicPattern)
Topology addSource(
  final TimestampExtractor timestampExtractor,
  final String name,
  final String... topics)
----

Adds a new <<kafka-streams-internals-SourceNode.adoc#, source node>> (with the optional <<AutoOffsetReset, AutoOffsetReset>> and <<kafka-streams-TimestampExtractor.adoc#, TimestampExtractor>>) to the topology.

| addStateStore
a| [[addStateStore]]

[source, java]
----
Topology addStateStore(
  final StoreBuilder storeBuilder,
  final String... processorNames)
----

Adds a new <<kafka-streams-StateStore.adoc#, StateStore>> (with the <<kafka-streams-StoreBuilder.adoc#, StoreBuilder>>) to the topology.

| connectProcessorAndStateStores
a| [[connectProcessorAndStateStores]]

[source, java]
----
Topology connectProcessorAndStateStores(
  final String processorName,
  final String... stateStoreNames)
----

Connects the <<kafka-streams-internals-ProcessorNode.adoc#, processor node>> with <<kafka-streams-StateStore.adoc#, state stores>> (by name).

| describe
a| [[describe]]

[source, java]
----
TopologyDescription describe()
----

Describes the topology.

|===

[[internalTopologyBuilder]]
Internally, `Topology` uses an <<kafka-streams-internals-InternalTopologyBuilder.adoc#, InternalTopologyBuilder>> in all <<operators, methods>> (and is therefore a thin layer atop).

.Topology and InternalTopologyBuilder
image::images/kafka-streams-Topology-InternalTopologyBuilder.png[align="center"]
