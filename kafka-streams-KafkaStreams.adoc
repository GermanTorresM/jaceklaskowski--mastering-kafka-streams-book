== [[KafkaStreams]] KafkaStreams

`KafkaStreams` is the entry point for *continuous message processing* in Kafka Streams.

`KafkaStreams` is "merely" a <<clientSupplier, Kafka client>> that consumes messages from one or many Kafka source topics (known as link:kafka-streams-SourceNode.adoc[SourceNodes]) and publishes the processing results to zero, one or more Kafka target topics (known as link:kafka-streams-SinkNode.adoc[SinkNodes]).

[[topology]]
`KafkaStreams` processes records through a topology.

NOTE: A Kafka Streams developer defines the processing logic either using a link:kafka-streams-Topology.adoc[Topology] directly (and define a DAG topology of link:kafka-streams-Processor.adoc[Processors]) or indirectly through a link:kafka-streams-StreamsBuilder.adoc[StreamsBuilder] that provides the high-level DSL to define transformations.

[source, scala]
----
import org.apache.kafka.streams.KafkaStreams
val topology: Topology = ...
val config: StreamsConfig = ...
val ks = new KafkaStreams(topology, config)
----

Once <<creating-instance, created>>, you should <<start, start>> `KafkaStreams` to start consuming, processing, and producing records (described in <<topology, Topology>>).

[source, scala]
----
ks.start()
----

[[internal-registries]]
.KafkaStreams's Internal Properties (e.g. Registries, Counters and Flags)
[cols="1,2",options="header",width="100%"]
|===
| Name
| Description

| `globalStreamThread`
a| [[globalStreamThread]] link:kafka-streams-GlobalStreamThread.adoc[GlobalStreamThread]

* Initialized exclusively when <<internalTopologyBuilder, InternalTopologyBuilder>> could link:kafka-streams-InternalTopologyBuilder.adoc#buildGlobalStateTopology[build a global ProcessorTopology]

* Started when `KafkaStreams` is being <<start, started>>

* Set to `null` while `KafkaStreams` is being <<close, closed>>

| [[adminClient]] `adminClient`
a| Administrative client for Kafka, i.e. https://kafka.apache.org/10/javadoc/org/apache/kafka/clients/admin/AdminClient.html[AdminClient], that supports managing and inspecting topics, brokers, configurations and ACLs.

* Created while `KafkaStreams` is being <<creating-instance, created>> for the only purpose of link:kafka-streams-StreamThread.adoc#create[creating a StreamThread] (which is actually passed along to a link:kafka-streams-TaskManager.adoc#adminClient[TaskManager])

* Closed while `KafkaStreams` is being <<close, closed>>

| [[stateDirectory]] `stateDirectory`
| link:kafka-streams-StateDirectory.adoc[StateDirectory]

| [[stateLock]] `stateLock`
| Object lock for...FIXME

| `threads`
a| [[threads]] link:kafka-streams-StreamThread.adoc[Stream processor threads] (aka `StreamThread`)

NOTE: The number of stream processor threads per KafkaStreams instance is controlled by link:kafka-streams-properties.adoc#num.stream.threads[num.stream.threads] configuration property with the default being 1 thread.

* Created when `KafkaStreams` is <<creating-instance, created>>
* Started when `KafkaStreams` is <<start, started>>
* Shut down when `KafkaStreams` is <<close, closed>>
|===

[[logging]]
[TIP]
====
Enable `DEBUG` logging level for `org.apache.kafka.streams.KafkaStreams` logger to see what happens inside.

Add the following line to `log4j.properties`:

```
log4j.logger.org.apache.kafka.streams.KafkaStreams=DEBUG
```

Refer to link:kafka-logging.adoc#log4j.properties[Application Logging Using log4j].
====

=== [[cleanUp]] Cleaning Up Local Directory of State Store -- `cleanUp` Method

[source, java]
----
void cleanUp()
----

`cleanUp` simply requests <<stateDirectory, StateDirectory>> to link:kafka-streams-StateDirectory.adoc#clean[clean] when `KafkaStreams` is not <<isRunning, running>>.

NOTE: `cleanUp` can only be executed before `KafkaStreams` will be <<start, started>> or after has been <<close, closed>>.

`cleanUp` reports a `IllegalStateException` when `KafkaStreams` is <<isRunning, running>>.

```
Cannot clean up while running.
```

=== [[isRunning]] `isRunning` Internal Method

[source, java]
----
boolean isRunning()
----

`isRunning`...FIXME

NOTE: `isRunning` is used when...FIXME

=== [[close]] Closing KafkaStreams -- `close` Method

[source, java]
----
void close()  // <1>
synchronized boolean close(final long timeout, final TimeUnit timeUnit)
----
<1> Calls `close(final long timeout, final TimeUnit timeUnit)` with 0 timeout

`close`...FIXME

IMPORTANT: Always execute `close` on a `KafkaStreams` instance even if you never call <<start, start>> to avoid resource leaks.

=== [[localThreadsMetadata]] `localThreadsMetadata` Method

[source, java]
----
Set<ThreadMetadata> localThreadsMetadata()
----

`localThreadsMetadata`...FIXME

NOTE: `localThreadsMetadata` is used when...FIXME

=== [[creating-instance]] Creating KafkaStreams Instance

[source, java]
----
// public API
KafkaStreams(
  final Topology topology,
  final Properties props) // <1>
KafkaStreams(
  final Topology topology,
  final StreamsConfig config) // <2>

// public API (mostly for testing)
KafkaStreams(
  final Topology topology,
  final StreamsConfig config,
  final KafkaClientSupplier clientSupplier) // <3>
KafkaStreams(
  final Topology topology,
  final StreamsConfig config,
  final Time time)  // <4>

// private/internal API
KafkaStreams(
  final InternalTopologyBuilder internalTopologyBuilder,
  final StreamsConfig config,
  final KafkaClientSupplier clientSupplier) // <5>
KafkaStreams(
  final InternalTopologyBuilder internalTopologyBuilder,
  final StreamsConfig config,
  final KafkaClientSupplier clientSupplier,
  final Time time)  // <6>
----
<1> Calls `KafkaStreams` (2) with `StreamsConfig` with the input `props`
<2> Calls `KafkaStreams` (3) with `DefaultKafkaClientSupplier`
<5> Calls the internal `KafkaStreams` (6) with `SystemTime`

`KafkaStreams` takes the following when created:

* [[internalTopologyBuilder]] link:kafka-streams-InternalTopologyBuilder.adoc[InternalTopologyBuilder]
* [[config]] link:kafka-streams-StreamsConfig.adoc[StreamsConfig]
* [[clientSupplier]] link:kafka-streams-KafkaClientSupplier.adoc[KafkaClientSupplier]
* [[time]] `Time`

`KafkaStreams` initializes the <<internal-registries, internal registries and counters>>.

=== [[setRunningFromCreated]] `setRunningFromCreated` Internal Method

[source, java]
----
boolean setRunningFromCreated()
----

`setRunningFromCreated`...FIXME

NOTE: `setRunningFromCreated` is used exclusively when `KafkaStreams` is <<start, started>>.

=== [[toString]] Describing Itself (Text Representation) -- `toString` Method

[source, java]
----
String toString() // <1>
String toString(final String indent)
----
<1> Calls `toString(final String indent)` with an empty indent, i.e. `""`

NOTE: `toString` with an indent is *deprecated* and should not be used. Use <<localThreadsMetadata, localThreadsMetadata>> instead.

`toString`...FIXME

=== [[start]] Starting KafkaStreams -- `start` Method

[source, java]
----
synchronized void start()
throws IllegalStateException, StreamsException
----

`start` starts the <<topology, Topology>> (that in turn starts consuming, processing, and producing records).

Internally, `start` prints out the following DEBUG message to the logs:

```
Starting Streams client
```

`start` <<setRunningFromCreated, marks KafkaStreams as running>> (i.e. transitions from CREATED to RUNNING state and notifies link:kafka-streams-StateListener.adoc[StateListeners]).

`start` starts <<globalStreamThread, global stream thread>> if defined (which is when...FIXME)

`start` starts <<threads, stream threads>>.

`start` schedules a thread that requests <<stateDirectory, StateDirectory>> to link:kafka-streams-StateDirectory.adoc#cleanRemovedTasks[cleanRemovedTasks] every link:kafka-streams-properties.adoc#state.cleanup.delay.ms[state.cleanup.delay.ms] milliseconds.

You should see the following DEBUG message in the logs:

```
Started Streams client
```

In case the <<setRunningFromCreated, changing state to running>> fails, `start` merely prints out the following ERROR message to the logs:

```
Already stopped, cannot re-start
```
