== [[KafkaStreams]] KafkaStreams

`KafkaStreams` is the <<operators, main interface>> for *stream processing* (of Kafka records) in a Kafka Streams application.

`KafkaStreams` is simply a <<clientSupplier, Kafka client>> that consumes messages from and produces the processing results to Kafka topics (abstracted as link:kafka-streams-SourceNode.adoc[SourceNodes] and link:kafka-streams-SinkNode.adoc[SinkNodes], respectively).

.KafkaStreams
image::images/kafka-streams-KafkaStreams.png[align="center"]

NOTE: A Kafka Streams developer describes the processing logic using a link:kafka-streams-Topology.adoc[Topology] directly (that is a graph of link:kafka-streams-Processor.adoc[processors]) or indirectly through a link:kafka-streams-StreamsBuilder.adoc[StreamsBuilder] that provides the high-level DSL to define transformations and build a stream processing topology.

[source, scala]
----
import org.apache.kafka.streams.KafkaStreams
val topology: Topology = ...

val config: StreamsConfig = ...
val ks = new KafkaStreams(topology, config)
----

Once <<creating-instance, created>>, `KafkaStreams` is <<start, started up>> to start consuming, processing, and producing records (as described by a <<topology, Topology>>).

[source, scala]
----
ks.start
----

(only when in <<state, CREATED>> state) `KafkaStreams` can be <<setGlobalStateRestoreListener, given>> a <<globalStateRestoreListener, StateRestoreListener>> to be informed about the state-related events: <<kafka-streams-DelegatingStateRestoreListener.adoc#onRestoreStart, onRestoreStart>>, <<kafka-streams-DelegatingStateRestoreListener.adoc#onBatchRestored, onBatchRestored>> and <<kafka-streams-DelegatingStateRestoreListener.adoc#onRestoreEnd, onRestoreEnd>> (through <<kafka-streams-DelegatingStateRestoreListener.adoc#, DelegatingStateRestoreListener>>).

[source, scala]
----
import org.apache.kafka.streams.processor.StateRestoreListener
val userRestoreListener: StateRestoreListener = ???
ks.setGlobalStateRestoreListener(userRestoreListener)
----

[[operators]]
.KafkaStreams API
[cols="1,2",options="header",width="100%"]
|===
| Method
| Description

| allMetadata
a| [[allMetadata]]

[source, java]
----
Collection<StreamsMetadata> allMetadata()
----

| allMetadataForStore
a| [[allMetadataForStore]]

[source, java]
----
Collection<StreamsMetadata> allMetadataForStore(final String storeName)
----

| <<cleanUp-detailed, cleanUp>>
a| [[cleanUp]]

[source, java]
----
void cleanUp()
----

Cleans up the local directory for state stores

| <<close-detailed, close>>
a| [[close]]

[source, java]
----
void close()
boolean close(final long timeout, final TimeUnit timeUnit)
----

Closes the `KafkaStreams`

| isRunning
a| [[isRunning]]

[source, java]
----
boolean isRunning()
----

| localThreadsMetadata
a| [[localThreadsMetadata]]

[source, java]
----
Set<ThreadMetadata> localThreadsMetadata()
----

| metadataForKey
a| [[metadataForKey]]

[source, java]
----
StreamsMetadata metadataForKey(
  final String storeName,
  final K key,
  final Serializer<K> keySerializer)
StreamsMetadata metadataForKey(
  final String storeName,
  final K key,
  final StreamPartitioner<? super K, ?> partitioner)
----

| metrics
a| [[metrics]]

[source, java]
----
Map<MetricName, ? extends Metric> metrics()
----

| <<setGlobalStateRestoreListener-detailed, setGlobalStateRestoreListener>>
a| [[setGlobalStateRestoreListener]]

[source, java]
----
void setGlobalStateRestoreListener(final StateRestoreListener globalStateRestoreListener)
----

Registers a global <<kafka-streams-StateRestoreListener.adoc#, StateRestoreListener>>

| setStateListener
a| [[setStateListener]]

[source, java]
----
void setStateListener(final KafkaStreams.StateListener listener)
----

| setUncaughtExceptionHandler
a| [[setUncaughtExceptionHandler]]

[source, java]
----
void setUncaughtExceptionHandler(final Thread.UncaughtExceptionHandler eh)
----

| <<start-detailed, start>>
a| [[start]]

[source, java]
----
void start() throws IllegalStateException, StreamsException
----

Starts the `KafkaStreams` (and the <<topology, Topology>>)

| state
a| [[state]]

[source, java]
----
State state()
----

| store
a| [[store]]

[source, java]
----
T store(final String storeName, final QueryableStoreType<T> queryableStoreType)
----
|===

`KafkaStreams` uses a <<internalTopologyBuilder, InternalTopologyBuilder>> for the following:

* Creating a <<streamsMetadataState, StreamsMetadataState>>, <<threads, StreamThreads>> and <<queryableStoreProvider, QueryableStoreProvider>>

* Requesting a <<kafka-streams-InternalTopologyBuilder.adoc#buildGlobalStateTopology, global processor topology>> (for a <<globalStreamThread, GlobalStreamThread>>)

[[internal-registries]]
.KafkaStreams's Internal Properties (e.g. Registries, Counters and Flags)
[cols="1m,2",options="header",width="100%"]
|===
| Name
| Description

| clientId
| [[clientId]]

| globalStateRestoreListener
a| [[globalStateRestoreListener]] A user-defined global <<kafka-streams-StateRestoreListener.adoc#, StateRestoreListener>> to be notified about the state-related events: <<kafka-streams-DelegatingStateRestoreListener.adoc#onRestoreStart, onRestoreStart>>, <<kafka-streams-DelegatingStateRestoreListener.adoc#onBatchRestored, onBatchRestored>> and <<kafka-streams-DelegatingStateRestoreListener.adoc#onRestoreEnd, onRestoreEnd>> (through <<kafka-streams-DelegatingStateRestoreListener.adoc#, DelegatingStateRestoreListener>>)

Set using <<setGlobalStateRestoreListener, setGlobalStateRestoreListener>> method

| globalStreamThread
a| [[globalStreamThread]] link:kafka-streams-GlobalStreamThread.adoc[GlobalStreamThread]

* Initialized exclusively when <<internalTopologyBuilder, InternalTopologyBuilder>> could link:kafka-streams-InternalTopologyBuilder.adoc#buildGlobalStateTopology[build a global ProcessorTopology]

* Started when `KafkaStreams` is being <<start, started>>

* Set to `null` while `KafkaStreams` is being <<close, closed>>

| adminClient
a| [[adminClient]] Kafka https://kafka.apache.org/20/javadoc/org/apache/kafka/clients/admin/AdminClient.html[AdminClient] (that allows for managing and inspecting topics, brokers, configurations and ACLs)

* Initialized when `KafkaStreams` is <<creating-instance-adminClient, created>> for the only purpose of link:kafka-streams-StreamThread.adoc#create[creating StreamThreads] (that simply use it to <<kafka-streams-TaskManager.adoc#adminClient, create a TaskManager>>)

* Closed when `KafkaStreams` is <<close, closed>>

| queryableStoreProvider
| [[queryableStoreProvider]] link:kafka-streams-QueryableStoreProvider.adoc[QueryableStoreProvider]

| stateDirectory
| [[stateDirectory]] link:kafka-streams-StateDirectory.adoc[StateDirectory]

| stateLock
| [[stateLock]] Object lock for...FIXME

| streamsMetadataState
| [[streamsMetadataState]] link:kafka-streams-StreamsMetadataState.adoc[StreamsMetadataState] (for the <<internalTopologyBuilder, InternalTopologyBuilder>> and link:kafka-streams-properties.adoc#application.server[application.server] configuration property)

| threads
a| [[threads]] <<kafka-streams-StreamThread.adoc#, Stream processor threads>>

NOTE: The number of stream processor threads per KafkaStreams instance is controlled by <<kafka-streams-properties.adoc#num.stream.threads, num.stream.threads>> configuration property (default: `1` processing thread).

* Created when `KafkaStreams` is <<creating-instance, created>>
* Started when `KafkaStreams` is <<start, started>>
* Shut down when `KafkaStreams` is <<close, closed>>
|===

[[logging]]
[TIP]
====
Enable `DEBUG` logging level for `org.apache.kafka.streams.KafkaStreams` logger to see what happens inside.

Add the following line to `log4j.properties`:

```
log4j.logger.org.apache.kafka.streams.KafkaStreams=DEBUG
```

Refer to link:kafka-logging.adoc#log4j.properties[Application Logging Using log4j].
====

=== [[cleanUp-detailed]] Cleaning Up Local Directory for State Stores -- `cleanUp` Method

[source, java]
----
void cleanUp()
----

`cleanUp` simply requests <<stateDirectory, StateDirectory>> to link:kafka-streams-StateDirectory.adoc#clean[clean] when `KafkaStreams` is not <<isRunning, running>>.

NOTE: `cleanUp` can only be executed before `KafkaStreams` will be <<start, started>> or after has been <<close, closed>>.

`cleanUp` reports a `IllegalStateException` when `KafkaStreams` is <<isRunning, running>>.

```
Cannot clean up while running.
```

=== [[close-detailed]] Closing KafkaStreams -- `close` Method

[source, java]
----
void close()  // <1>
synchronized boolean close(final long timeout, final TimeUnit timeUnit)
----
<1> Calls `close(final long timeout, final TimeUnit timeUnit)` with 0 timeout

`close`...FIXME

IMPORTANT: Always execute `close` on a `KafkaStreams` instance even if you never call <<start, start>> to avoid resource leaks.

=== [[creating-instance]] Creating KafkaStreams Instance

[source, java]
----
// public API
KafkaStreams(
  final Topology topology,
  final Properties props) // <1>

// public API (mostly for testing)
KafkaStreams(
  final Topology topology,
  final Properties props,
  final KafkaClientSupplier clientSupplier) // <3>
KafkaStreams(
  final Topology topology,
  final Properties props,
  final Time time)  // <4>

// private/internal API
KafkaStreams(
  final InternalTopologyBuilder internalTopologyBuilder,
  final StreamsConfig config,
  final KafkaClientSupplier clientSupplier) // <5>
KafkaStreams(
  final InternalTopologyBuilder internalTopologyBuilder,
  final StreamsConfig config,
  final KafkaClientSupplier clientSupplier,
  final Time time)  // <6>
----
<1> Calls the internal `KafkaStreams` (5) with a new DefaultKafkaClientSupplier
<5> Calls the internal `KafkaStreams` (6) with `SystemTime`

`KafkaStreams` takes the following when created:

* [[internalTopologyBuilder]] link:kafka-streams-InternalTopologyBuilder.adoc[InternalTopologyBuilder]
* [[config]] link:kafka-streams-StreamsConfig.adoc[StreamsConfig]
* [[clientSupplier]] link:kafka-streams-KafkaClientSupplier.adoc[KafkaClientSupplier]
* [[time]] `Time`

`KafkaStreams` initializes the <<internal-registries, internal registries and counters>>.

While being created, `KafkaStreams`...FIXME

[[creating-instance-adminClient]]
`KafkaStreams` requests the input <<kafka-streams-KafkaClientSupplier.adoc#, KafkaClientSupplier>> for a <<kafka-streams-KafkaClientSupplier.adoc#getAdminClient, Kafka AdminClient>> (given the <<kafka-streams-StreamsConfig.adoc#getAdminConfigs, AdminClient configuration>> for the <<clientId, clientId>>).

=== [[setRunningFromCreated]] `setRunningFromCreated` Internal Method

[source, java]
----
boolean setRunningFromCreated()
----

`setRunningFromCreated`...FIXME

NOTE: `setRunningFromCreated` is used exclusively when `KafkaStreams` is <<start, started>>.

=== [[toString]] Describing Itself (Text Representation) -- `toString` Method

[source, java]
----
String toString() // <1>
String toString(final String indent)
----
<1> Calls `toString(final String indent)` with an empty indent, i.e. `""`

NOTE: `toString` with an indent is *deprecated* and should not be used. Use <<localThreadsMetadata, localThreadsMetadata>> instead.

`toString`...FIXME

=== [[start-detailed]] Starting KafkaStreams -- `start` Method

[source, java]
----
synchronized void start()
throws IllegalStateException, StreamsException
----

`start` starts the <<topology, Topology>> (that in turn starts consuming, processing, and producing records).

Internally, `start` prints out the following DEBUG message to the logs:

```
Starting Streams client
```

`start` <<setRunningFromCreated, marks KafkaStreams as running>> (i.e. transitions from CREATED to RUNNING state and notifies link:kafka-streams-StateListener.adoc[StateListeners]).

`start` starts <<globalStreamThread, global stream thread>> if defined (which is when...FIXME)

`start` starts <<threads, stream threads>>.

`start` schedules a thread that requests <<stateDirectory, StateDirectory>> to link:kafka-streams-StateDirectory.adoc#cleanRemovedTasks[cleanRemovedTasks] every link:kafka-streams-properties.adoc#state.cleanup.delay.ms[state.cleanup.delay.ms] milliseconds.

You should see the following DEBUG message in the logs:

```
Started Streams client
```

In case the <<setRunningFromCreated, changing state to running>> fails, `start` merely prints out the following ERROR message to the logs:

```
Already stopped, cannot re-start
```

=== [[setGlobalStateRestoreListener-detailed]] Registering Global StateRestoreListener -- `setGlobalStateRestoreListener` Method

[source, java]
----
void setGlobalStateRestoreListener(final StateRestoreListener globalStateRestoreListener)
----

`setGlobalStateRestoreListener` registers a <<kafka-streams-StateRestoreListener.adoc#, StateRestoreListener>> (in a Kafka Streams application).

Internally, `setGlobalStateRestoreListener` simply sets the <<globalStateRestoreListener, globalStateRestoreListener>> internal property to be the input <<kafka-streams-StateRestoreListener.adoc#, StateRestoreListener>> (only when in <<state, CREATED>> state).

`setGlobalStateRestoreListener` throws a `IllegalStateException` when not in <<state, CREATED>> state:

```
Can only set GlobalStateRestoreListener in CREATED state. Current state is: [state]
```
