== [[KafkaStreams]] KafkaStreams -- Streams Client

`KafkaStreams` is the <<operators, interface>> for managing and inspecting the execution environment of the <<topology, processing topology>> of a Kafka Streams application.

NOTE: A `KafkaStreams` instance is also referred by the name *streams client* (esp. in logs).

A `KafkaStreams` instance (process) can be <<start, started>> or <<close, closed>> (_shut down_). The current state is available using <<state, state>>.

[[isRunning]]
`KafkaStreams` is running when the <<state, state>> is either `RUNNING` or `REBALANCING`.

There could be many `KafkaStreams` instances running simultaneously (e.g. as separate JVM processes each with its own <<threads, StreamThreads>>). While a `KafkaStreams` instance is running, it allows for inspecting <<kafka-streams-StreamsMetadataState.adoc#StreamsMetadata, streams metadata>> using <<allMetadata, allMetadata>>, <<allMetadataForStore, allMetadataForStore>>, and <<metadataForKey, metadataForKey>> methods.

A `KafkaStreams` instance exposes <<metrics, monitoring metrics>> (incl. the Kafka Producer, Consumers, and AdminClient).

Only when in `CREATED` state, a `KafkaStreams` instance can be registered with <<setGlobalStateRestoreListener, StateRestoreListeners>>, <<setStateListener, StateListeners>>, and <<setUncaughtExceptionHandler, UncaughtExceptionHandlers>>.

[[operators]]
.KafkaStreams API
[cols="1m,2",options="header",width="100%"]
|===
| Method
| Description

| <<allMetadata-internals, allMetadata>>
a| [[allMetadata]]

[source, java]
----
Collection<StreamsMetadata> allMetadata()
----

<<kafka-streams-StreamsMetadataState.adoc#StreamsMetadatas, StreamsMetadatas>> for all instances in a <<kafka-streams-multi-instance-kafka-streams-application.adoc#, multi-instance Kafka Streams application>>

| allMetadataForStore
a| [[allMetadataForStore]]

[source, java]
----
Collection<StreamsMetadata> allMetadataForStore(
  final String storeName)
----

| <<cleanUp-internals, cleanUp>>
a| [[cleanUp]]

[source, java]
----
void cleanUp()
----

Cleans up the local directory with state stores

| <<close-internals, close>>
a| [[close]]

[source, java]
----
void close()
boolean close(final Duration timeout)
----

Closes the `KafkaStreams`

| localThreadsMetadata
a| [[localThreadsMetadata]]

[source, java]
----
Set<ThreadMetadata> localThreadsMetadata()
----

| metadataForKey
a| [[metadataForKey]]

[source, java]
----
StreamsMetadata metadataForKey(
  final String storeName,
  final K key,
  final Serializer<K> keySerializer)
StreamsMetadata metadataForKey(
  final String storeName,
  final K key,
  final StreamPartitioner<? super K, ?> partitioner)
----

| metrics
a| [[metrics]]

[source, java]
----
Map<MetricName, ? extends Metric> metrics()
----

Kafka http://kafka.apache.org/21/javadoc/index.html?org/apache/kafka/common/Metric.html[monitoring metrics] of the `KafkaStreams` instance (incl. the Kafka `Producer`, `Consumers`, and `AdminClient` used by the <<threads, StreamThreads>>)

| <<setGlobalStateRestoreListener-internals, setGlobalStateRestoreListener>>
a| [[setGlobalStateRestoreListener]]

[source, java]
----
void setGlobalStateRestoreListener(
  final StateRestoreListener globalStateRestoreListener)
----

Registers a global <<kafka-streams-StateRestoreListener.adoc#, StateRestoreListener>>

| setStateListener
a| [[setStateListener]]

[source, java]
----
void setStateListener(
  final KafkaStreams.StateListener listener)
----

| setUncaughtExceptionHandler
a| [[setUncaughtExceptionHandler]]

[source, java]
----
void setUncaughtExceptionHandler(
  final Thread.UncaughtExceptionHandler eh)
----

| <<start-internals, start>>
a| [[start]]

[source, java]
----
void start()
----

Starts the `KafkaStreams` (and the <<topology, Topology>>)

| state
a| [[state]]

[source, java]
----
State state()
----

The current state of the `KafkaStreams` instance

| store
a| [[store]]

[source, java]
----
T store(
  final String storeName,
  final QueryableStoreType<T> queryableStoreType)
----
|===

`KafkaStreams` is simply a <<clientSupplier, Kafka client>> that consumes messages from and produces the processing results to Kafka topics (abstracted as link:kafka-streams-internals-SourceNode.adoc[SourceNodes] and link:kafka-streams-internals-SinkNode.adoc[SinkNodes], respectively).

.KafkaStreams
image::images/kafka-streams-KafkaStreams.png[align="center"]

NOTE: A Kafka Streams developer describes the processing logic using a link:kafka-streams-Topology.adoc[Topology] directly (that is a graph of link:kafka-streams-Processor.adoc[processors]) or indirectly through a link:kafka-streams-StreamsBuilder.adoc[StreamsBuilder] that provides the high-level DSL to define transformations and build a stream processing topology.

[source, scala]
----
import org.apache.kafka.streams.KafkaStreams
val topology: Topology = ...

val config: StreamsConfig = ...
val ks = new KafkaStreams(topology, config)
----

Once <<creating-instance, created>>, `KafkaStreams` is <<start, started up>> to start consuming, processing, and producing records (as described by a <<topology, Topology>>).

[source, scala]
----
ks.start
----

(only when in <<state, CREATED>> state) `KafkaStreams` can be <<setGlobalStateRestoreListener, given>> a <<globalStateRestoreListener, StateRestoreListener>> to be informed about the state-related events: <<kafka-streams-DelegatingStateRestoreListener.adoc#onRestoreStart, onRestoreStart>>, <<kafka-streams-DelegatingStateRestoreListener.adoc#onBatchRestored, onBatchRestored>> and <<kafka-streams-DelegatingStateRestoreListener.adoc#onRestoreEnd, onRestoreEnd>> (through <<kafka-streams-DelegatingStateRestoreListener.adoc#, DelegatingStateRestoreListener>>).

[source, scala]
----
import org.apache.kafka.streams.processor.StateRestoreListener
val userRestoreListener: StateRestoreListener = ???
ks.setGlobalStateRestoreListener(userRestoreListener)
----

`KafkaStreams` uses a <<internalTopologyBuilder, InternalTopologyBuilder>> for the following:

* Creating a <<streamsMetadataState, StreamsMetadataState>>, <<threads, StreamThreads>> and <<queryableStoreProvider, QueryableStoreProvider>>

* Requesting a <<kafka-streams-internals-InternalTopologyBuilder.adoc#buildGlobalStateTopology, global processor topology>> (for a <<globalStreamThread, GlobalStreamThread>>)

[[internal-registries]]
.KafkaStreams's Internal Properties (e.g. Registries, Counters and Flags)
[cols="1m,2",options="header",width="100%"]
|===
| Name
| Description

| clientId
| [[clientId]]

| globalStateRestoreListener
a| [[globalStateRestoreListener]] A user-defined global <<kafka-streams-StateRestoreListener.adoc#, StateRestoreListener>> to be notified about the state-related events: <<kafka-streams-DelegatingStateRestoreListener.adoc#onRestoreStart, onRestoreStart>>, <<kafka-streams-DelegatingStateRestoreListener.adoc#onBatchRestored, onBatchRestored>> and <<kafka-streams-DelegatingStateRestoreListener.adoc#onRestoreEnd, onRestoreEnd>> (through <<kafka-streams-DelegatingStateRestoreListener.adoc#, DelegatingStateRestoreListener>>)

Set using <<setGlobalStateRestoreListener, setGlobalStateRestoreListener>> method

| globalStreamThread
a| [[globalStreamThread]] link:kafka-streams-internals-GlobalStreamThread.adoc[GlobalStreamThread]

* Initialized exclusively when <<internalTopologyBuilder, InternalTopologyBuilder>> could link:kafka-streams-internals-InternalTopologyBuilder.adoc#buildGlobalStateTopology[build a global ProcessorTopology]

* Started when `KafkaStreams` is being <<start, started>>

* Set to `null` while `KafkaStreams` is being <<close, closed>>

| adminClient
a| [[adminClient]] Kafka https://kafka.apache.org/21/javadoc/org/apache/kafka/clients/admin/AdminClient.html[AdminClient] (that allows for managing and inspecting topics, brokers, configurations and ACLs)

* Initialized when `KafkaStreams` is <<creating-instance-adminClient, created>> for the only purpose of <<kafka-streams-StreamThread.adoc#create, creating StreamThreads>> (that simply use it to <<kafka-streams-TaskManager.adoc#adminClient, create a TaskManager>>)

* Closed when `KafkaStreams` is <<close, closed>>

| queryableStoreProvider
| [[queryableStoreProvider]] link:kafka-streams-QueryableStoreProvider.adoc[QueryableStoreProvider]

| stateDirectory
| [[stateDirectory]] link:kafka-streams-internals-StateDirectory.adoc[StateDirectory]

| stateLock
| [[stateLock]] Object lock for...FIXME

| streamsMetadataState
a| [[streamsMetadataState]] <<kafka-streams-StreamsMetadataState.adoc#, StreamsMetadataState>> (with the <<internalTopologyBuilder, InternalTopologyBuilder>> and <<kafka-streams-properties.adoc#application.server, application.server>> configuration property)

`KafkaStreams` is simply a public facade to expose the <<streamsMetadataState, StreamsMetadataState>> using the following methods:

* <<allMetadata, allMetadata>>

* <<allMetadataForStore, allMetadataForStore>>

* <<metadataForKey, metadataForKey>>

Initialized when `KafkaStreams` is <<creating-instance, created>> to <<kafka-streams-StreamThread.adoc#create, create StreamThreads>>

| threads
a| [[threads]] <<kafka-streams-StreamThread.adoc#, Stream processor threads>>

NOTE: The number of stream processor threads per KafkaStreams instance is controlled by <<kafka-streams-properties.adoc#num.stream.threads, num.stream.threads>> configuration property (default: `1` processing thread).

* Created when `KafkaStreams` is <<creating-instance, created>>
* Started when `KafkaStreams` is <<start, started>>
* Shut down when `KafkaStreams` is <<close, closed>>
|===

[[logging]]
[TIP]
====
Enable `DEBUG` logging level for `org.apache.kafka.streams.KafkaStreams` logger to see what happens inside.

Add the following line to `log4j.properties`:

```
log4j.logger.org.apache.kafka.streams.KafkaStreams=DEBUG
```

Refer to link:kafka-logging.adoc#log4j.properties[Application Logging Using log4j].
====

=== [[cleanUp-internals]] Cleaning Up Local Directory for State Stores -- `cleanUp` Method

[source, java]
----
void cleanUp()
----

`cleanUp` simply requests <<stateDirectory, StateDirectory>> to link:kafka-streams-internals-StateDirectory.adoc#clean[clean] when `KafkaStreams` is not <<isRunning, running>>.

NOTE: `cleanUp` can only be executed before `KafkaStreams` will be <<start, started>> or after has been <<close, closed>>.

`cleanUp` reports a `IllegalStateException` when `KafkaStreams` is <<isRunning, running>>.

```
Cannot clean up while running.
```

=== [[close-internals]] Closing KafkaStreams -- `close` Method

[source, java]
----
void close()  // <1>
synchronized boolean close(final long timeout, final TimeUnit timeUnit)
----
<1> Calls `close(final long timeout, final TimeUnit timeUnit)` with 0 timeout

`close`...FIXME

IMPORTANT: Always execute `close` on a `KafkaStreams` instance even if you never call <<start, start>> to avoid resource leaks.

=== [[creating-instance]] Creating KafkaStreams Instance

[source, java]
----
// public API
KafkaStreams(
  final Topology topology,
  final Properties props) // <1>

// public API (mostly for testing)
KafkaStreams(
  final Topology topology,
  final Properties props,
  final KafkaClientSupplier clientSupplier) // <3>
KafkaStreams(
  final Topology topology,
  final Properties props,
  final Time time)  // <4>

// private/internal API
KafkaStreams(
  final InternalTopologyBuilder internalTopologyBuilder,
  final StreamsConfig config,
  final KafkaClientSupplier clientSupplier) // <5>
KafkaStreams(
  final InternalTopologyBuilder internalTopologyBuilder,
  final StreamsConfig config,
  final KafkaClientSupplier clientSupplier,
  final Time time)  // <6>
----
<1> Calls the internal `KafkaStreams` (5) with a new DefaultKafkaClientSupplier
<5> Calls the internal `KafkaStreams` (6) with `SystemTime`

`KafkaStreams` takes the following when created:

* [[internalTopologyBuilder]] link:kafka-streams-internals-InternalTopologyBuilder.adoc[InternalTopologyBuilder]
* [[config]] link:kafka-streams-StreamsConfig.adoc[StreamsConfig]
* [[clientSupplier]] link:kafka-streams-KafkaClientSupplier.adoc[KafkaClientSupplier]
* [[time]] `Time`

`KafkaStreams` initializes the <<internal-registries, internal registries and counters>>.

While being created, `KafkaStreams`...FIXME

[[creating-instance-adminClient]]
`KafkaStreams` requests the input <<kafka-streams-KafkaClientSupplier.adoc#, KafkaClientSupplier>> for a <<kafka-streams-KafkaClientSupplier.adoc#getAdminClient, Kafka AdminClient>> (for the <<kafka-streams-StreamsConfig.adoc#getAdminConfigs, AdminClient configuration>> for the <<clientId, clientId>>).

=== [[setRunningFromCreated]] `setRunningFromCreated` Internal Method

[source, java]
----
boolean setRunningFromCreated()
----

`setRunningFromCreated`...FIXME

NOTE: `setRunningFromCreated` is used exclusively when `KafkaStreams` is <<start, started>>.

=== [[start-internals]] Starting KafkaStreams -- `start` Method

[source, java]
----
synchronized void start()
throws IllegalStateException, StreamsException
----

`start` starts the <<topology, Topology>> (that in turn starts consuming, processing, and producing records).

Internally, `start` prints out the following DEBUG message to the logs:

```
Starting Streams client
```

`start` <<setRunningFromCreated, marks KafkaStreams as running>> (i.e. transitions from CREATED to RUNNING state and notifies link:kafka-streams-StateListener.adoc[StateListeners]).

`start` starts <<globalStreamThread, global stream thread>> if defined (which is when...FIXME)

`start` starts <<threads, stream threads>>.

`start` schedules a thread that requests <<stateDirectory, StateDirectory>> to link:kafka-streams-internals-StateDirectory.adoc#cleanRemovedTasks[cleanRemovedTasks] every link:kafka-streams-properties.adoc#state.cleanup.delay.ms[state.cleanup.delay.ms] milliseconds.

You should see the following DEBUG message in the logs:

```
Started Streams client
```

In case the <<setRunningFromCreated, changing state to running>> fails, `start` merely prints out the following ERROR message to the logs:

```
Already stopped, cannot re-start
```

=== [[setGlobalStateRestoreListener-internals]] Registering Global StateRestoreListener -- `setGlobalStateRestoreListener` Method

[source, java]
----
void setGlobalStateRestoreListener(final StateRestoreListener globalStateRestoreListener)
----

`setGlobalStateRestoreListener` registers a <<kafka-streams-StateRestoreListener.adoc#, StateRestoreListener>> (in a Kafka Streams application).

Internally, `setGlobalStateRestoreListener` simply sets the <<globalStateRestoreListener, globalStateRestoreListener>> internal property to be the input <<kafka-streams-StateRestoreListener.adoc#, StateRestoreListener>> (only when in <<state, CREATED>> state).

`setGlobalStateRestoreListener` throws a `IllegalStateException` when not in <<state, CREATED>> state:

```
Can only set GlobalStateRestoreListener in CREATED state. Current state is: [state]
```

=== [[allMetadata-internals]] `allMetadata` Method

[source, java]
----
Collection<StreamsMetadata> allMetadata()
----

`allMetadata` <<validateIsRunning, makes sure that KafkaStreams is running>> and requests the <<streamsMetadataState, StreamsMetadataState>> for <<kafka-streams-StreamsMetadataState.adoc#getAllMetadata, metadata>>.

=== [[validateIsRunning]] Making Sure That KafkaStreams Is Running -- `validateIsRunning` Internal Method

[source, java]
----
void validateIsRunning()
----

`validateIsRunning` throws a `IllegalStateException` when `KafkaStreams` is not <<isRunning, running>>. Otherwise, `validateIsRunning` does nothing.

```
KafkaStreams is not running. State is [state].
```

NOTE: `validateIsRunning` is used when `KafkaStreams` is requested to <<allMetadata, allMetadata>>, <<allMetadataForStore, allMetadataForStore>>, <<metadataForKey, metadataForKey>>, <<metadataForKey, metadataForKey>>, <<store, store>>, and <<localThreadsMetadata, localThreadsMetadata>>.
