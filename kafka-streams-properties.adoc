== Configuration Properties

.Configuration Properties
[cols="1m,1,2",options="header",width="100%"]
|===
| Name
| Default Value
| Description

| application.id
| (empty)
a| [[application.id]] *Application ID* that is the required identifier of a Kafka Streams stream processing application

It must be unique within the Kafka cluster as it is used as a namespace for the default client-id prefix, the group-id for membership management, and the prefix for internal topics (that Kafka Streams creates internally).

`application.id` is used as a Kafka consumer group ID (that you can check out using `kafka-consumer-groups.sh` script)

Use <<kafka-streams-StreamsConfig.adoc#APPLICATION_ID_CONFIG, StreamsConfig.APPLICATION_ID_CONFIG>> to reference the property.

| application.server
| (empty)
| [[application.server]] A `host:port` pair of a user-defined endpoint of a single instance in <<kafka-streams-multi-instance-kafka-streams-application.adoc#, multi-instance Kafka Streams application>> that can be used for discovering the locations of local state stores

Used exclusively when `StreamPartitionAssignor` is requested to <<kafka-streams-internals-StreamsPartitionAssignor.adoc#configure, configure itself>>.

Use <<kafka-streams-StreamsConfig.adoc#APPLICATION_SERVER_CONFIG, StreamsConfig.APPLICATION_SERVER_CONFIG>> to reference the property.

| cache.max.bytes.buffering
| `10MB` (10 * 1024 * 1024L)
| [[cache.max.bytes.buffering]] Maximum number of memory bytes to be used for buffering across all (processor and global) threads

Use <<kafka-streams-StreamsConfig.adoc#CACHE_MAX_BYTES_BUFFERING_CONFIG, StreamsConfig.CACHE_MAX_BYTES_BUFFERING_CONFIG>> to reference the property.

| client.id
| (empty)
a| [[client.id]] Client ID of internal consumer, producer and restore-consumer, with pattern `<client.id>-StreamThread-<threadSequenceNumber>-<consumer,producer,restore-consumer>`

Used when:

* `KafkaStreams` is <<kafka-streams-KafkaStreams.adoc#, created>> (and initializes the <<kafka-streams-KafkaStreams.adoc#clientId, clientId>> internal property)

* `StreamsPartitionAssignor` is requested to <<kafka-streams-internals-StreamsPartitionAssignor.adoc#configure, configure>>

Use <<kafka-streams-StreamsConfig.adoc#CLIENT_ID_CONFIG, StreamsConfig.CLIENT_ID_CONFIG>> to reference the property.

| commit.interval.ms
a|
* `100L` when <<processing.guarantee, processing.guarantee>> is <<exactly_once, exactly_once>> (which is not by default)
* `30000L` otherwise
a| [[commit.interval.ms]] *Flush interval* or *commit interval* (in millis), i.e. how often `StreamThread` <<kafka-streams-StreamThread.adoc#maybeCommit, tries to commit>> the position of processors and _flush_ state stores

Use <<kafka-streams-StreamsConfig.adoc#COMMIT_INTERVAL_MS_CONFIG, StreamsConfig.COMMIT_INTERVAL_MS_CONFIG>> to reference the property.

If the commit interval is negative, `StreamThread` will never <<kafka-streams-StreamThread.adoc#maybeCommit, commit tasks>>.

| default.windowed.key.serde.inner
| (empty)
| [[default.windowed.key.serde.inner]] Inner serde class that implements the `org.apache.kafka.common.serialization.Serde` interface

Use <<kafka-streams-StreamsConfig.adoc#DEFAULT_WINDOWED_KEY_SERDE_INNER_CLASS, StreamsConfig.DEFAULT_WINDOWED_KEY_SERDE_INNER_CLASS>> to reference the property.

| default.windowed.value.serde.inner
| (empty)
| [[default.windowed.value.serde.inner]] Inner serde class that implements the `org.apache.kafka.common.serialization.Serde` interface

Use <<kafka-streams-StreamsConfig.adoc#DEFAULT_WINDOWED_VALUE_SERDE_INNER_CLASS, StreamsConfig.DEFAULT_WINDOWED_VALUE_SERDE_INNER_CLASS>> to reference the property.

| default.timestamp.extractor
| <<kafka-streams-FailOnInvalidTimestamp.adoc#, FailOnInvalidTimestamp>>
| [[default.timestamp.extractor]] Default timestamp extractor class that implements the <<kafka-streams-TimestampExtractor.adoc#, org.apache.kafka.streams.processor.TimestampExtractor>> interface.

| metrics.recording.level
| `INFO`
a| [[metrics.recording.level]] The highest recording level for <<kafka-streams-StreamsMetrics.adoc#, metrics>>

Possible values are:

* [[metrics.recording.level-INFO]] `INFO` (default)
* [[metrics.recording.level-DEBUG]] `DEBUG`

Use <<kafka-streams-StreamsConfig.adoc#METRICS_RECORDING_LEVEL_CONFIG, StreamsConfig.METRICS_RECORDING_LEVEL_CONFIG>> to reference the property.

| num.standby.replicas
| `0`
a| [[num.standby.replicas]] The number of standby replicas per processing task

* Used when `StreamsPartitionAssignor` is requested to <<kafka-streams-internals-StreamsPartitionAssignor.adoc#configure, configure>>

Use <<kafka-streams-StreamsConfig.adoc#NUM_STANDBY_REPLICAS_CONFIG, StreamsConfig.NUM_STANDBY_REPLICAS_CONFIG>> to reference the property.

| num.stream.threads
| `1`
| [[num.stream.threads]] The number of <<kafka-streams-StreamThread.adoc#, stream processor threads>> (that <<kafka-streams-KafkaStreams.adoc#threads, KafkaStreams>> uses for stream processing).

| partition.grouper
|
a| [[partition.grouper]]

| poll.ms
| `100`
a| [[poll.ms]] *Polling interval* (in milliseconds), i.e. the time spent waiting in `Consumer.poll` (unless data is available in the buffer). If `0`, returns immediately with any records that are available currently in the buffer, else returns empty. Must not be negative.

* Used when `GlobalStreamThread` is requested to link:kafka-streams-internals-GlobalStreamThread.adoc#initialize[initialize] (which is right after `KafkaStreams` has been link:kafka-streams-KafkaStreams.adoc#start[started]) and creates a link:kafka-streams-StateConsumer.adoc#pollMs[StateConsumer]

* Used when `StreamThread` is link:kafka-streams-StreamThread.adoc#pollTimeMs[created]

Use <<kafka-streams-StreamsConfig.adoc#POLL_MS_CONFIG, StreamsConfig.POLL_MS_CONFIG>> to reference the property.

| processing.guarantee
| `at_least_once`
a| [[processing.guarantee]] *Processing guarantee* (aka _Exactly-Once Support_ or _EOS support_)

Possible values are:

* [[at_least_once]] *at_least_once* (default)
* [[exactly_once]] *exactly_once*

[NOTE]
====
<<exactly_once, exactly-once>> processing guarantee requires a Kafka cluster with at least three brokers (which is the recommended setting for production).

For development you can change this by adjusting broker setting `transaction.state.log.replication.factor`.
====

Use <<kafka-streams-StreamsConfig.adoc#PROCESSING_GUARANTEE_CONFIG, StreamsConfig.PROCESSING_GUARANTEE_CONFIG>> to reference the property.

| replication.factor
| `1`
| [[replication.factor]] The replication factor for change log topics and repartition topics created by a stream processing application

Use <<kafka-streams-StreamsConfig.adoc#REPLICATION_FACTOR_CONFIG, StreamsConfig.REPLICATION_FACTOR_CONFIG>> to reference the property.

| state.cleanup.delay.ms
| `10` mins (`10 * 60 * 1000`)
| [[state.cleanup.delay.ms]] The amount of time (in milliseconds) to wait before deleting state when a partition has migrated. Only state directories that have not been modified for at least `state.cleanup.delay.ms` will be removed.

| state.dir
| `/tmp/kafka-streams`
a| [[state.dir]] Path to the base directory for a state storage

* Used when `StateDirectory` is link:kafka-streams-internals-StateDirectory.adoc#creating-instance[created]

Use <<kafka-streams-StreamsConfig.adoc#STATE_DIR_CONFIG, StreamsConfig.STATE_DIR_CONFIG>> to reference the property.

| windowstore.changelog.additional.retention.ms
| `24 * 60 * 60 * 1000L`
| [[windowstore.changelog.additional.retention.ms]] Added to a Window `maintainMs` to ensure data is not deleted from the log prematurely. Allows for clock drift. Default is 1 day

|===
