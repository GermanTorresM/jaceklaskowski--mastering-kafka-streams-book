== Configuration Properties

.Configuration Properties
[cols="1m,1",options="header",width="100%"]
|===
| Name
| Description

| application.id
a| [[application.id]] *Application ID* that is the required identifier of a Kafka Streams stream processing application

Default: (empty)

`application.id` must be unique within the Kafka cluster as it is used as a namespace for the default client-id prefix, the group-id for membership management, and the prefix for internal topics (that Kafka Streams creates internally).

`application.id` is used as a Kafka consumer group ID (that you can check out using `kafka-consumer-groups.sh` script)

Use <<kafka-streams-StreamsConfig.adoc#APPLICATION_ID_CONFIG, StreamsConfig.APPLICATION_ID_CONFIG>> to reference the property.

| application.server
| [[application.server]] A `host:port` pair of a user-defined endpoint of a single instance in <<kafka-streams-multi-instance-kafka-streams-application.adoc#, multi-instance Kafka Streams application>> that can be used for discovering the locations of local state stores

Default: (empty)

Used exclusively when `StreamPartitionAssignor` is requested to <<kafka-streams-internals-StreamsPartitionAssignor.adoc#configure, configure itself>>.

Use <<kafka-streams-StreamsConfig.adoc#APPLICATION_SERVER_CONFIG, StreamsConfig.APPLICATION_SERVER_CONFIG>> to reference the property.

| buffered.records.per.partition
| [[buffered.records.per.partition]] Maximum number of records to buffer per partition

Default: `1000`

Used exclusively when `StreamTask` is requested to <<kafka-streams-internals-StreamTask.adoc#process, process a single record>> and <<kafka-streams-internals-StreamTask.adoc#addRecords, buffer new records>> to resume and pause a partition, respectively

Use <<kafka-streams-StreamsConfig.adoc#BUFFERED_RECORDS_PER_PARTITION_CONFIG, StreamsConfig.BUFFERED_RECORDS_PER_PARTITION_CONFIG>> to reference the property.

| cache.max.bytes.buffering
| [[cache.max.bytes.buffering]] Maximum number of memory bytes to be used for buffering across all (processor and global) threads

Default: `10 * 1024 * 1024L` (i.e. `10MB`)

Use <<kafka-streams-StreamsConfig.adoc#CACHE_MAX_BYTES_BUFFERING_CONFIG, StreamsConfig.CACHE_MAX_BYTES_BUFFERING_CONFIG>> to reference the property.

| client.id
a| [[client.id]] Client ID of internal consumer, producer and restore-consumer, with pattern `<client.id>-StreamThread-<threadSequenceNumber>-<consumer,producer,restore-consumer>`

Default: (empty)

Used when:

* `KafkaStreams` is <<kafka-streams-KafkaStreams.adoc#, created>> (and initializes the <<kafka-streams-KafkaStreams.adoc#clientId, clientId>> internal property)

* `StreamsPartitionAssignor` is requested to <<kafka-streams-internals-StreamsPartitionAssignor.adoc#configure, configure>>

Use <<kafka-streams-StreamsConfig.adoc#CLIENT_ID_CONFIG, StreamsConfig.CLIENT_ID_CONFIG>> to reference the property.

| commit.interval.ms
a| [[commit.interval.ms]] *Flush interval* or *commit interval* (in millis), i.e. how often `StreamThread` <<kafka-streams-internals-StreamThread.adoc#maybeCommit, attempts to commit>> the position of processors and _flush_ state stores

Default:

* `100L` when <<processing.guarantee, processing.guarantee>> is <<exactly_once, exactly_once>> (which is not by default)
* `30000L` (`30s`) otherwise

Must be at least `0L`

Use <<kafka-streams-StreamsConfig.adoc#COMMIT_INTERVAL_MS_CONFIG, StreamsConfig.COMMIT_INTERVAL_MS_CONFIG>> to reference the property.

| default.windowed.key.serde.inner
a| [[default.windowed.key.serde.inner]] Inner serde class that implements the `org.apache.kafka.common.serialization.Serde` interface

Default: (empty)

Use <<kafka-streams-StreamsConfig.adoc#DEFAULT_WINDOWED_KEY_SERDE_INNER_CLASS, StreamsConfig.DEFAULT_WINDOWED_KEY_SERDE_INNER_CLASS>> to reference the property.

| default.windowed.value.serde.inner
a| [[default.windowed.value.serde.inner]] Inner serde class that implements the `org.apache.kafka.common.serialization.Serde` interface

Default: (empty)

Use <<kafka-streams-StreamsConfig.adoc#DEFAULT_WINDOWED_VALUE_SERDE_INNER_CLASS, StreamsConfig.DEFAULT_WINDOWED_VALUE_SERDE_INNER_CLASS>> to reference the property.

| default.timestamp.extractor
a| [[default.timestamp.extractor]] Default timestamp extractor class that implements the <<kafka-streams-TimestampExtractor.adoc#, org.apache.kafka.streams.processor.TimestampExtractor>> interface.

Default: <<kafka-streams-FailOnInvalidTimestamp.adoc#, FailOnInvalidTimestamp>>

| max.task.idle.ms
a| [[max.task.idle.ms]] How long a <<kafka-streams-internals-StreamTask.adoc#, stream task>> will stay idle when not all of its partition buffers contain records, to avoid potential out-of-order record processing across multiple input streams.

Default: `0L`

Use <<kafka-streams-StreamsConfig.adoc#MAX_TASK_IDLE_MS_CONFIG, StreamsConfig.MAX_TASK_IDLE_MS_CONFIG>> to reference the property.

| metrics.recording.level
a| [[metrics.recording.level]] The highest recording level for <<kafka-streams-StreamsMetrics.adoc#, metrics>>

Default: `INFO`

Possible values are:

* [[metrics.recording.level-INFO]] `INFO`
* [[metrics.recording.level-DEBUG]] `DEBUG`

Use <<kafka-streams-StreamsConfig.adoc#METRICS_RECORDING_LEVEL_CONFIG, StreamsConfig.METRICS_RECORDING_LEVEL_CONFIG>> to reference the property.

| num.standby.replicas
a| [[num.standby.replicas]] The number of standby replicas per processing task

Default: `0`

* Used when `StreamsPartitionAssignor` is requested to <<kafka-streams-internals-StreamsPartitionAssignor.adoc#configure, configure>>

Use <<kafka-streams-StreamsConfig.adoc#NUM_STANDBY_REPLICAS_CONFIG, StreamsConfig.NUM_STANDBY_REPLICAS_CONFIG>> to reference the property.

| num.stream.threads
a| [[num.stream.threads]] The number of <<kafka-streams-internals-StreamThread.adoc#, stream processor threads>> (that <<kafka-streams-KafkaStreams.adoc#threads, KafkaStreams>> uses for stream processing)

Default: `1`

Use <<kafka-streams-StreamsConfig.adoc#NUM_STREAM_THREADS_CONFIG, StreamsConfig.NUM_STREAM_THREADS_CONFIG>> to reference the property.

| partition.grouper
a| [[partition.grouper]]

| poll.ms
a| [[poll.ms]] *Polling interval* (in milliseconds), i.e. the time spent waiting in link:++https://kafka.apache.org/22/javadoc/org/apache/kafka/clients/consumer/KafkaConsumer.html#poll-java.time.Duration-++[Consumer.poll] (unless data is available in the buffer already). If `0`, returns immediately with any records that are available currently in the buffer, else returns empty. Must not be negative.

Default: `100`

Used when:

* `GlobalStreamThread` is requested to <<kafka-streams-internals-GlobalStreamThread.adoc#initialize, initialize>> (which is right after `KafkaStreams` has been requested to <<kafka-streams-KafkaStreams.adoc#start, start>>) and creates a <<kafka-streams-StateConsumer.adoc#pollMs, StateConsumer>>

* `StreamThread` is <<kafka-streams-internals-StreamThread.adoc#pollTime, created>>

Use <<kafka-streams-StreamsConfig.adoc#POLL_MS_CONFIG, StreamsConfig.POLL_MS_CONFIG>> to reference the property.

| processing.guarantee
a| [[processing.guarantee]] *Processing guarantee* (aka _Exactly-Once Support_ or _EOS support_)

Default: `at_least_once`

Possible values are:

* [[at_least_once]] *at_least_once*
* [[exactly_once]] *exactly_once*

[NOTE]
====
<<exactly_once, exactly-once>> processing guarantee requires a Kafka cluster with at least three brokers (which is the recommended setting for production).

For development you can change this by adjusting broker setting `transaction.state.log.replication.factor`.
====

Use <<kafka-streams-StreamsConfig.adoc#PROCESSING_GUARANTEE_CONFIG, StreamsConfig.PROCESSING_GUARANTEE_CONFIG>> to reference the property.

| replication.factor
a| [[replication.factor]] The replication factor for changelog topics and repartition topics created by a stream processing application

Default: `1`

Use <<kafka-streams-StreamsConfig.adoc#REPLICATION_FACTOR_CONFIG, StreamsConfig.REPLICATION_FACTOR_CONFIG>> to reference the property.

| state.cleanup.delay.ms
a| [[state.cleanup.delay.ms]] The amount of time (in milliseconds) to wait before deleting state when a partition has migrated. Only state directories that have not been modified for at least `state.cleanup.delay.ms` will be removed.

Default: `10 * 60 * 1000` (i.e. `10 mins`)

Used exclusively when `KafkaStreams` is <<kafka-streams-KafkaStreams.adoc#stateDirCleaner, created>>

Use <<kafka-streams-StreamsConfig.adoc#STATE_CLEANUP_DELAY_MS_CONFIG, StreamsConfig.STATE_CLEANUP_DELAY_MS_CONFIG>> to reference the property.

| state.dir
a| [[state.dir]] Path to the base directory for a state storage

Default: `/tmp/kafka-streams`

Used when `StateDirectory` is link:kafka-streams-internals-StateDirectory.adoc#creating-instance[created]

Use <<kafka-streams-StreamsConfig.adoc#STATE_DIR_CONFIG, StreamsConfig.STATE_DIR_CONFIG>> to reference the property.

| windowstore.changelog.additional.retention.ms
a| [[windowstore.changelog.additional.retention.ms]] Added to a Window `maintainMs` to ensure data is not deleted from the log prematurely. Allows for clock drift.

Default: `24 * 60 * 60 * 1000L` (i.e. `1 day`)

|===
