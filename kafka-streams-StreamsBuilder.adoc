== [[StreamsBuilder]] StreamsBuilder

`StreamsBuilder` provides the <<operators, high-level stream processing DSL>> in Kafka Streams to <<build, build a processor topology>> (with sources, processors, and sinks).

[[operators]]
.StreamsBuilder's Operators
[cols="1,2",options="header",width="100%"]
|===
| Operator
| Description

| <<addGlobalStore, addGlobalStore>>
| Adds a global link:kafka-streams-StateStore.adoc[StateStore] to the topology

| <<addStateStore, addStateStore>>
| Adds a link:kafka-streams-StateStore.adoc[StateStore] to the topology

| <<globalTable, globalTable>>
| Creates a link:kafka-streams-GlobalKTable.adoc[GlobalKTable] for a given topic

| <<stream, stream>>
| Creates a link:kafka-streams-KStream.adoc[KStream] from given topics

| <<table, table>>
| Create a link:kafka-streams-KTable.adoc[KTable] for a given topic
|===

[[creating-instance]]
`StreamsBuilder` takes no arguments when created.

[source, scala]
----
import org.apache.kafka.streams.StreamsBuilder
val builder = new StreamsBuilder
----

A typical Kafka Streams application uses the <<operators, high-level stream processing DSL>> to add nodes to a processor topology as follows.

[source, scala]
----
// Add a GlobalKTable with a global store if needed
builder
  .addGlobalStore(...)
  .globalTable(...)

// Add a KStream if needed
builder.stream(...)

// Add a KTable if needed
builder.table(...)

// In the end, build a topology
val topology = builder.build
----

[[topology]]
When <<creating-instance, created>>, `StreamsBuilder` creates a link:kafka-streams-Topology.adoc#creating-instance[Topology] (that is further developed using the <<operators, operators>>). The `Topology` is then requested for the link:kafka-streams-Topology.adoc#internalTopologyBuilder[InternalTopologyBuilder] that is used to create the <<internalStreamsBuilder, InternalStreamsBuilder>>.

[[internalStreamsBuilder]]
When <<creating-instance, created>>, `StreamsBuilder` creates an link:kafka-streams-InternalStreamsBuilder.adoc#creating-instance[InternalStreamsBuilder] that the <<operators, operators>> use to offer their services.

NOTE: `StreamsBuilder` simply provides a more developer-friendly API for stream processing than using the link:kafka-streams-InternalStreamsBuilder.adoc[InternalStreamsBuilder] API directly. In other words, `StreamsBuilder` is a fa√ßade of `InternalStreamsBuilder`.

=== [[table]] Creating KTable -- `table` Method

[source, java]
----
KTable<K, V> table(final String topic)
KTable<K, V> table(final String topic, final Consumed<K, V> consumed)
KTable<K, V> table(
  final String topic,
  final Consumed<K, V> consumed,
  final Materialized<K, V, KeyValueStore<Bytes, byte[]>> materialized)
KTable<K, V> table(
  final String topic,
  final Materialized<K, V, KeyValueStore<Bytes, byte[]>> materialized)
----

`table`...FIXME

=== [[globalTable]] Creating GlobalKTable -- `globalTable` Method

[source, java]
----
synchronized <K, V> GlobalKTable<K, V> globalTable(final String topic)
synchronized <K, V> GlobalKTable<K, V> globalTable(
  final String topic,
  final Consumed<K, V> consumed)
synchronized <K, V> GlobalKTable<K, V> globalTable(
  final String topic,
  final Consumed<K, V> consumed,
  final Materialized<K, V, KeyValueStore<Bytes, byte[]>> materialized)
synchronized <K, V> GlobalKTable<K, V> globalTable(
  final String topic,
  final Materialized<K, V, KeyValueStore<Bytes, byte[]>> materialized)
----

`globalTable`...FIXME

[source, scala]
----
import org.apache.kafka.streams.StreamsBuilder
val builder = new StreamsBuilder
val globalTable = builder.globalTable[String, String]("global-table")
val topology = builder.build
scala> println(topology.describe)
Topologies:
   Sub-topology: 0 for global store (will not generate tasks)
    Source: KSTREAM-SOURCE-0000000001 (topics: global-table)
      --> KTABLE-SOURCE-0000000002
    Processor: KTABLE-SOURCE-0000000002 (stores: [global-table-STATE-STORE-0000000000])
      --> none
      <-- KSTREAM-SOURCE-0000000001
----

=== [[addGlobalStore]] `addGlobalStore` Method

[source, java]
----
synchronized StreamsBuilder addGlobalStore(
  final StoreBuilder storeBuilder,
  final String topic,
  final Consumed consumed,
  final ProcessorSupplier stateUpdateSupplier)
----

`addGlobalStore`...FIXME

=== [[addStateStore]] `addStateStore` Method

[source, java]
----
StreamsBuilder addStateStore(final StoreBuilder builder)
----

`addStateStore`...FIXME

=== [[stream]] Reading Topic (Creating KStream of Records from One or Many Topics) -- `stream` Method

[source, java]
----
synchronized <K, V> KStream<K, V> stream(final String topic)  // <1>
synchronized <K, V> KStream<K, V> stream(final Pattern topicPattern) // <2>
synchronized <K, V> KStream<K, V> stream(final Collection<String> topics) // <3>
// All three above have their Consumed-based variant
synchronized <K, V> KStream<K, V> stream(
  final String topic,
  final Consumed<K, V> consumed)
synchronized <K, V> KStream<K, V> stream(
  final Pattern topicPattern,
  final Consumed<K, V> consumed)
synchronized <K, V> KStream<K, V> stream(
  final Collection<String> topics,
  final Consumed<K, V> consumed)
----
<1> Calls `stream(final Collection<String> topics)`
<2> Calls `stream(final Pattern topicPattern, final Consumed<K, V> consumed)` with `Consumed` with all fields `null`
<3> Calls `stream(final Collection<String> topics, final Consumed<K, V> consumed)` with `Consumed` with all fields `null`

`stream` creates a link:kafka-streams-KStream.adoc[KStream] (of keys of type `K` and values of type `V`) for the defined topic(s) and the parameters in the input link:kafka-streams-Consumed.adoc[Consumed].

[source, scala]
----
scala> :type builder
org.apache.kafka.streams.StreamsBuilder

// Create a KStream to read records from the input topic
// Keys and values of the records are of String type
val input = builder.stream[String, String]("input")

scala> :type input
org.apache.kafka.streams.kstream.KStream[String,String]
----

Internally, `stream` creates a link:kafka-streams-ConsumedInternal.adoc#creating-instance[ConsumedInternal] (for the input link:kafka-streams-Consumed.adoc[Consumed]) and requests the <<internalStreamsBuilder, InternalStreamsBuilder>> to link:kafka-streams-InternalStreamsBuilder.adoc#stream[create a KStream] (for the input `topics` and the `ConsumedInternal`).
